{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-5-nano'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dd65e-90af-4ca8-86b6-23a41840645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://patents.google.com/patent/US20210049536A1/',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://edwarddonner.com/2025/11/11/ai-live-event/',\n",
       " 'https://edwarddonner.com/2025/11/11/ai-live-event/',\n",
       " 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       " 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = fetch_website_links(\"https://edwarddonner.com\")\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-5-nano figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-5-nano to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "You should respond in JSON as in this example:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e4068-97ed-4120-beae-c42105e4d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2025/11/11/ai-live-event/\n",
      "https://edwarddonner.com/2025/11/11/ai-live-event/\n",
      "https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/\n",
      "https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(\"https://edwarddonner.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effeb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    return links\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490de841",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_relevant_links(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b84c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26709d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    print(f\"Selecting relevant links for {url} by calling {MODEL}\")\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    print(f\"Found {len(links['links'])} relevant links\")\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/microsoft/VibeVoice-Realtime-0.5B',\n",
       " '/Tongyi-MAI/Z-Image-Turbo',\n",
       " '/zai-org/GLM-4.6V-Flash',\n",
       " '/zai-org/GLM-4.6V',\n",
       " '/mistralai/Devstral-Small-2-24B-Instruct-2512',\n",
       " '/models',\n",
       " '/spaces/Tongyi-MAI/Z-Image-Turbo',\n",
       " '/spaces/mrfakename/Z-Image-Turbo',\n",
       " '/spaces/OpenEvals/evaluation-guidebook',\n",
       " '/spaces/dream2589632147/Dream-wan2-2-faster-Pro',\n",
       " '/spaces/anycoderapps/VibeVoice-Realtime-0.5B',\n",
       " '/spaces',\n",
       " '/datasets/Anthropic/AnthropicInterviewer',\n",
       " '/datasets/TuringEnterprises/Turing-Open-Reasoning',\n",
       " '/datasets/nvidia/PhysicalAI-Autonomous-Vehicles',\n",
       " '/datasets/nvidia/ToolScale',\n",
       " '/datasets/openai/gdpval',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/inference/models',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/changelog',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord',\n",
       " 'https://www.zhihu.com/org/huggingface',\n",
       " 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/chinese-language-blog/wechat.jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'home page', 'url': 'https://huggingface.co/'},\n",
       "  {'type': 'brand page', 'url': 'https://huggingface.co/brand'},\n",
       "  {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'},\n",
       "  {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'},\n",
       "  {'type': 'blog', 'url': 'https://huggingface.co/blog'},\n",
       "  {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'},\n",
       "  {'type': 'GitHub', 'url': 'https://github.com/huggingface'},\n",
       "  {'type': 'Twitter', 'url': 'https://twitter.com/huggingface'},\n",
       "  {'type': 'LinkedIn page',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/'},\n",
       "  {'type': 'Zhihu page', 'url': 'https://www.zhihu.com/org/huggingface'},\n",
       "  {'type': 'Community forum', 'url': 'https://discuss.huggingface.co'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT-5-nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'docs page', 'url': 'https://huggingface.co/docs'}, {'type': 'brand page', 'url': 'https://huggingface.co/brand'}, {'type': 'learn page', 'url': 'https://huggingface.co/learn'}, {'type': 'blog', 'url': 'https://huggingface.co/blog'}, {'type': 'community forum', 'url': 'https://discuss.huggingface.co'}, {'type': 'status page', 'url': 'https://status.huggingface.co/'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter profile', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn profile', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'Product endpoints', 'url': 'https://endpoints.huggingface.co'}, {'type': 'Discord community', 'url': 'https://huggingface.co/join/discord'}, {'type': 'Changelog', 'url': 'https://huggingface.co/changelog'}]}\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Hugging Face ‚Äì The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "microsoft/VibeVoice-Realtime-0.5B\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "80.2k\n",
      "‚Ä¢\n",
      "732\n",
      "Tongyi-MAI/Z-Image-Turbo\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "245k\n",
      "‚Ä¢\n",
      "2.55k\n",
      "zai-org/GLM-4.6V-Flash\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "18.6k\n",
      "‚Ä¢\n",
      "349\n",
      "zai-org/GLM-4.6V\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "2.21k\n",
      "‚Ä¢\n",
      "268\n",
      "mistralai/Devstral-Small-2-24B-Instruct-2512\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "7.22k\n",
      "‚Ä¢\n",
      "267\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "1.31k\n",
      "Z Image Turbo\n",
      "üèÉ\n",
      "1.31k\n",
      "Generate images from text prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "479\n",
      "Z Image Turbo\n",
      "üñº\n",
      "479\n",
      "Generate stunning images from text prompts\n",
      "Running\n",
      "181\n",
      "Evaluation Guidebook\n",
      "üìù\n",
      "181\n",
      "Display evaluation metrics for LLM benchmarks\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "906\n",
      "Dream-wan2-2-faster-Pro\n",
      "üé¨\n",
      "906\n",
      "Generate videos from images using prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "1.58k\n",
      "Qwen Image Edit Camera Control\n",
      "üé¨\n",
      "1.58k\n",
      "Fast 4 step inference with Qwen Image Edit 2509\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "Anthropic/AnthropicInterviewer\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "7.04k\n",
      "‚Ä¢\n",
      "223\n",
      "TuringEnterprises/Turing-Open-Reasoning\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "5.96k\n",
      "‚Ä¢\n",
      "97\n",
      "nvidia/PhysicalAI-Autonomous-Vehicles\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "183k\n",
      "‚Ä¢\n",
      "500\n",
      "nvidia/ToolScale\n",
      "Updated\n",
      "15 days ago\n",
      "‚Ä¢\n",
      "2.44k\n",
      "‚Ä¢\n",
      "115\n",
      "openai/gdpval\n",
      "Updated\n",
      "Sep 25\n",
      "‚Ä¢\n",
      "25.1k\n",
      "‚Ä¢\n",
      "343\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "Inference Providers\n",
      "Access 45,000+ models from leading AI providers through a single, unified API with no service fees.\n",
      "Explore Models\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Team\n",
      "non-profit\n",
      "‚Ä¢\n",
      "821 models\n",
      "‚Ä¢\n",
      "4.75k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "2.27k models\n",
      "‚Ä¢\n",
      "9.81k followers\n",
      "Amazon\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "21 models\n",
      "‚Ä¢\n",
      "3.64k followers\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "1.05k models\n",
      "‚Ä¢\n",
      "38.1k followers\n",
      "Intel\n",
      "company\n",
      "‚Ä¢\n",
      "261 models\n",
      "‚Ä¢\n",
      "3.27k followers\n",
      "Microsoft\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "428 models\n",
      "‚Ä¢\n",
      "17k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "11 models\n",
      "‚Ä¢\n",
      "196 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "32 models\n",
      "‚Ä¢\n",
      "371 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "153,757\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "32,032\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,547\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "3,120\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "10,300\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "16,615\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "15,074\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "24,388\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "20,259\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,977\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,697\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "9,366\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Careers\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "enterprise page\n",
      "Webpage Title:\n",
      "Enterprise Hub - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Team & Enterprise Hub\n",
      "Scale your organization with the world‚Äôs leading AI platform\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore flexible contract options\n",
      "Give your organization the most advanced platform to build AI with enterprise-grade security, access controls,\n",
      "\t\t\tdedicated support and more.\n",
      "Single Sign-On\n",
      "Connect securely to your identity provider with SSO integration.\n",
      "Regions\n",
      "Select, manage, and audit the location of your repository data.\n",
      "Audit Logs\n",
      "Stay in control with comprehensive logs that report on actions taken.\n",
      "Resource Groups\n",
      "Accurately manage access to repositories with granular access control.\n",
      "Token Management\n",
      "Centralized token control and custom approval policies for organization access.\n",
      "Analytics\n",
      "Track and analyze repository usage data in a single dashboard.\n",
      "Advanced Compute Options\n",
      "Increase scalability and performance with more compute options like ZeroGPU.\n",
      "ZeroGPU Quota Boost\n",
      "All organization members get 5x more ZeroGPU quota to get the most of Spaces.\n",
      "Private Datasets Viewer\n",
      "Enable the Dataset Viewer on your private datasets for easier collaboration.\n",
      "Private Storage\n",
      "Get an additional 1 TB of private storage for each member of your organization (then $25/month per extra TB).\n",
      "Inference Providers\n",
      "Enable organization billing for Inference Providers, monitor usage with analytics, and manage spending limits.\n",
      "Advanced security\n",
      "Configure organization-wide security policies and default repository visibility.\n",
      "Billing\n",
      "Control your budget effectively with managed billing and yearly commit options.\n",
      "Priority Support\n",
      "Maximize your platform usage with priority support from the Hugging Face team.\n",
      "Join the most forward-thinking AI organizations\n",
      "Everything you already know and love about Hugging Face in Enterprise mode.\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore flexible contract options\n",
      "NVIDIA\n",
      "Enterprise\n",
      "+\n",
      "company\n",
      "‚Ä¢\n",
      "597 models\n",
      "‚Ä¢\n",
      "44.9k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "2.27k models\n",
      "‚Ä¢\n",
      "9.81k followers\n",
      "Nerdy Face\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "1 model\n",
      "‚Ä¢\n",
      "349 followers\n",
      "JetBrains\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "17 models\n",
      "‚Ä¢\n",
      "738 followers\n",
      "Together\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "33 models\n",
      "‚Ä¢\n",
      "743 followers\n",
      "Qwen\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "392 models\n",
      "‚Ä¢\n",
      "60.8k followers\n",
      "InstaDeep Ltd\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "55 models\n",
      "‚Ä¢\n",
      "359 followers\n",
      "Toyota Research Institute\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "10 models\n",
      "‚Ä¢\n",
      "161 followers\n",
      "IBM Research\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "324 models\n",
      "‚Ä¢\n",
      "410 followers\n",
      "Roblox Corporation\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "6 models\n",
      "‚Ä¢\n",
      "332 followers\n",
      "Novo Nordisk R&ED\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "81 followers\n",
      "Aledade Inc\n",
      "Enterprise\n",
      "+\n",
      "company\n",
      "‚Ä¢\n",
      "73 followers\n",
      "Red Hat AI\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "552 models\n",
      "‚Ä¢\n",
      "1.71k followers\n",
      "HyperCLOVA X\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "4 models\n",
      "‚Ä¢\n",
      "704 followers\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "1.05k models\n",
      "‚Ä¢\n",
      "38.1k followers\n",
      "Shopify\n",
      "Enterprise\n",
      "+\n",
      "company\n",
      "‚Ä¢\n",
      "601 followers\n",
      "Orange\n",
      "Enterprise\n",
      "+\n",
      "company\n",
      "‚Ä¢\n",
      "10 models\n",
      "‚Ä¢\n",
      "315 followers\n",
      "Tenstorrent Inc.\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "248 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "32 models\n",
      "‚Ä¢\n",
      "371 followers\n",
      "ServiceNow\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "4 models\n",
      "‚Ä¢\n",
      "587 followers\n",
      "ServiceNow-AI\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "6 models\n",
      "‚Ä¢\n",
      "615 followers\n",
      "BAIDU\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "30 models\n",
      "‚Ä¢\n",
      "1.69k followers\n",
      "Airbnb\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "111 followers\n",
      "FuriosaAI\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "22 models\n",
      "‚Ä¢\n",
      "121 followers\n",
      "MiniMax\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "11 models\n",
      "‚Ä¢\n",
      "2.77k followers\n",
      "Twelve Labs\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "80 followers\n",
      "Mistral AI_\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "65 models\n",
      "‚Ä¢\n",
      "13.8k followers\n",
      "H2O.ai\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "75 models\n",
      "‚Ä¢\n",
      "470 followers\n",
      "Meta Llama\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "70 models\n",
      "‚Ä¢\n",
      "70.1k followers\n",
      "AMD\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "285 models\n",
      "‚Ä¢\n",
      "2.14k followers\n",
      "Arm\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "2 models\n",
      "‚Ä¢\n",
      "327 followers\n",
      "Microsoft\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "428 models\n",
      "‚Ä¢\n",
      "17k followers\n",
      "DoorDash\n",
      "Enterprise\n",
      "+\n",
      "company\n",
      "‚Ä¢\n",
      "185 followers\n",
      "PaloAltoNetworks\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "226 followers\n",
      "OpenAI\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "37 models\n",
      "‚Ä¢\n",
      "28.4k followers\n",
      "IBM Granite\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "178 models\n",
      "‚Ä¢\n",
      "3.66k followers\n",
      "TNG Technology Consulting GmbH\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "5 models\n",
      "‚Ä¢\n",
      "286 followers\n",
      "StepFun\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "33 models\n",
      "‚Ä¢\n",
      "1.62k followers\n",
      "Technology Innovation Institute\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "107 models\n",
      "‚Ä¢\n",
      "1.71k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "11 models\n",
      "‚Ä¢\n",
      "196 followers\n",
      "Fortis Games\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "58 followers\n",
      "HiddenLayer\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "1 model\n",
      "‚Ä¢\n",
      "81 followers\n",
      "Compliance & Certifications\n",
      "GDPR Compliant\n",
      "SOC 2 Type 2\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Careers\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "pricing page\n",
      "Webpage Title:\n",
      "Hugging Face ‚Äì Pricing\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Pricing\n",
      "Leveling up AI collaboration and compute.\n",
      "Give your personal account or your organization the most advanced platform to build AI.\n",
      "PRO\n",
      "PRO Account\n",
      "Boost your personal HF experience\n",
      "Subscribe for\n",
      "$9\n",
      "per month\n",
      "Get PRO\n",
      "10√ó private storage capacity\n",
      "20√ó included inference credits\n",
      "8√ó ZeroGPU quota and highest queue priority\n",
      "Spaces Dev Mode & ZeroGPU Spaces hosting\n",
      "Publish blog articles on your HF profile\n",
      "Dataset Viewer for private datasets\n",
      "Show your support with a Pro badge\n",
      "Team\n",
      "Instant setup for growing teams\n",
      "Subscribe for\n",
      "$20\n",
      "per user per month\n",
      "Get Team (via credit card)\n",
      "SSO and SAML support\n",
      "Choose data location with Storage Regions\n",
      "Detailed action reviews with Audit Logs\n",
      "Granular access control via Resource Groups\n",
      "Repository usage Analytics\n",
      "Set auth policies and default repository visibility\n",
      "Centralized token control and approvals\n",
      "Dataset Viewer for private datasets\n",
      "Advanced compute options for Spaces\n",
      "All organization members get ZeroGPU and Inference Providers PRO benefits\n",
      "Enterprise\n",
      "Custom onboarding and enterprise features\n",
      "Starting at\n",
      "$50\n",
      "per user per month\n",
      "Contact Sales\n",
      "All benefits from the Team plan\n",
      "Highest storage, bandwidth, and API rate limits\n",
      "Managed billing with annual commitments\n",
      "Legal and Compliance processes\n",
      "Personalized support\n",
      "Need support to adopt the HF Hub in your organization? View our\n",
      "Expert Support\n",
      ".\n",
      "Hugging Face Hub\n",
      "free\n",
      "The HF Hub is the central place to explore, experiment, collaborate and build technology with Machine\n",
      "\t\t\t\t\tLearning.\n",
      "Join the open source Machine Learning movement!\n",
      "‚Üí\n",
      "Sign Up\n",
      "Create with ML\n",
      "Packed with ML features, like model eval, dataset viewer and much more.\n",
      "Collaborate\n",
      "Git based and designed for collaboration at its core.\n",
      "Play and learn\n",
      "Learn by experimenting and sharing with our awesome community.\n",
      "Build your ML portfolio\n",
      "Share your work with the world and build your own ML profile.\n",
      "Spaces Hardware\n",
      "Starting at $0\n",
      "Spaces are one of the most popular ways to share ML applications and demos with the world.\n",
      "Upgrade your Spaces with our selection of custom on-demand hardware:\n",
      "‚Üí\n",
      "Get started with Spaces\n",
      "Name\n",
      "CPU\n",
      "Memory\n",
      "Accelerator\n",
      "VRAM\n",
      "Hourly price\n",
      "CPU Basic\n",
      "2 vCPU\n",
      "16 GB\n",
      "-\n",
      "-\n",
      "FREE\n",
      "CPU Upgrade\n",
      "8 vCPU\n",
      "32 GB\n",
      "-\n",
      "-\n",
      "$0.03\n",
      "Nvidia T4 - small\n",
      "4 vCPU\n",
      "15 GB\n",
      "Nvidia T4\n",
      "16 GB\n",
      "$0.40\n",
      "Nvidia T4 - medium\n",
      "8 vCPU\n",
      "30 GB\n",
      "Nvidia T4\n",
      "16 GB\n",
      "$0.60\n",
      "1x Nvidia L4\n",
      "8 vCPU\n",
      "30 GB\n",
      "Nvidia L4\n",
      "24 GB\n",
      "$0.80\n",
      "4x Nvidia L4\n",
      "48 vCPU\n",
      "186 GB\n",
      "Nvidia L4\n",
      "96 GB\n",
      "$3.80\n",
      "1x Nvidia L40S\n",
      "8 vCPU\n",
      "62 GB\n",
      "Nvidia L4\n",
      "48 GB\n",
      "$1.80\n",
      "4x Nvidia L40S\n",
      "48 vCPU\n",
      "382 GB\n",
      "Nvidia L4\n",
      "192 GB\n",
      "$8.30\n",
      "8x Nvidia L40S\n",
      "192 vCPU\n",
      "1534 GB\n",
      "Nvidia L4\n",
      "384 GB\n",
      "$23.50\n",
      "Nvidia A10G - small\n",
      "4 vCPU\n",
      "15 GB\n",
      "Nvidia A10G\n",
      "24 GB\n",
      "$1.00\n",
      "Nvidia A10G - large\n",
      "12 vCPU\n",
      "46 GB\n",
      "Nvidia A10G\n",
      "24 GB\n",
      "$1.50\n",
      "2x Nvidia A10G - large\n",
      "24 vCPU\n",
      "92 GB\n",
      "Nvidia A10G\n",
      "48 GB\n",
      "$3.00\n",
      "4x Nvidia A10G - large\n",
      "48 vCPU\n",
      "184 GB\n",
      "Nvidia A10G\n",
      "96 GB\n",
      "$5.00\n",
      "Nvidia A100 - large\n",
      "12 vCPU\n",
      "142 GB\n",
      "Nvidia A100\n",
      "80 GB\n",
      "$2.50\n",
      "Nvidia H100\n",
      "23 vCPU\n",
      "240 GB\n",
      "Nvidia H100\n",
      "80 GB\n",
      "$4.50\n",
      "8x Nvidia H100\n",
      "184 vCPU\n",
      "1920 GB\n",
      "Nvidia H100\n",
      "640 GB\n",
      "$36.00\n",
      "Custom\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "ZeroGPU\n",
      "dynamic\n",
      "dynamic\n",
      "Nvidia H200\n",
      "70 GB\n",
      "FREE\n",
      "Building something cool as a side project? We also offer community GPU grants.\n",
      "Inference Endpoints\n",
      "Starting at $0.033/hour\n",
      "Inference Endpoints (dedicated) offers a secure production solution to easily deploy any ML model on dedicated\n",
      "\t\t\t\t\tand autoscaling infrastructure, right from the HF Hub.\n",
      "‚Üí\n",
      "Learn more\n",
      "CPU\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "vCPUs\n",
      "Memory\n",
      "Hourly rate\n",
      "aws\n",
      "Intel Sapphire Rapids\n",
      "1\n",
      "2GB\n",
      "$0.03\n",
      "2\n",
      "4GB\n",
      "$0.07\n",
      "4\n",
      "8GB\n",
      "$0.13\n",
      "8\n",
      "16GB\n",
      "$0.27\n",
      "16\n",
      "32GB\n",
      "$0.54\n",
      "aws\n",
      "Intel Sapphire Rapids (overcommit)\n",
      "16\n",
      "32GB\n",
      "$0.01\n",
      "azure\n",
      "Intel Xeon\n",
      "1\n",
      "2GB\n",
      "$0.06\n",
      "2\n",
      "4GB\n",
      "$0.12\n",
      "4\n",
      "8GB\n",
      "$0.24\n",
      "8\n",
      "16GB\n",
      "$0.48\n",
      "gcp\n",
      "Intel Sapphire Rapids\n",
      "1\n",
      "2GB\n",
      "$0.05\n",
      "2\n",
      "4GB\n",
      "$0.10\n",
      "4\n",
      "8GB\n",
      "$0.20\n",
      "8\n",
      "16GB\n",
      "$0.40\n",
      "Accelerator\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "Topology\n",
      "Accelerator Memory\n",
      "Hourly rate\n",
      "aws\n",
      "Inf2\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tNeuron\n",
      "x1\n",
      "14.5GB\n",
      "$0.75\n",
      "x12\n",
      "760GB\n",
      "$12.00\n",
      "gcp\n",
      "TPU\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tv5e\n",
      "1x1\n",
      "16GB\n",
      "$1.20\n",
      "2x2\n",
      "64GB\n",
      "$4.75\n",
      "2x4\n",
      "128GB\n",
      "$9.50\n",
      "GPU\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "GPUs\n",
      "GPU Memory\n",
      "Hourly rate\n",
      "aws\n",
      "NVIDIA T4\n",
      "1\n",
      "14GB\n",
      "$0.50\n",
      "4\n",
      "56GB\n",
      "$3.00\n",
      "aws\n",
      "NVIDIA L4\n",
      "1\n",
      "24GB\n",
      "$0.80\n",
      "4\n",
      "96GB\n",
      "$3.80\n",
      "aws\n",
      "NVIDIA L40S\n",
      "1\n",
      "48GB\n",
      "$1.80\n",
      "4\n",
      "192GB\n",
      "$8.30\n",
      "8\n",
      "384GB\n",
      "$23.50\n",
      "aws\n",
      "NVIDIA A10G\n",
      "1\n",
      "24GB\n",
      "$1.00\n",
      "4\n",
      "96GB\n",
      "$5.00\n",
      "aws\n",
      "NVIDIA A100\n",
      "1\n",
      "80GB\n",
      "$2.50\n",
      "2\n",
      "160GB\n",
      "$5.00\n",
      "4\n",
      "320GB\n",
      "$10.00\n",
      "8\n",
      "640GB\n",
      "$20.00\n",
      "aws\n",
      "NVIDIA H100\n",
      "1\n",
      "80GB\n",
      "$4.50\n",
      "2\n",
      "160GB\n",
      "$9.00\n",
      "4\n",
      "320GB\n",
      "$18.00\n",
      "8\n",
      "640GB\n",
      "$36.00\n",
      "aws\n",
      "NVIDIA H200\n",
      "1\n",
      "141GB\n",
      "$5.00\n",
      "2\n",
      "282GB\n",
      "$10.00\n",
      "4\n",
      "564GB\n",
      "$20.00\n",
      "8\n",
      "1128GB\n",
      "$40.00\n",
      "aws\n",
      "NVIDIA B200\n",
      "1\n",
      "179GB\n",
      "$9.25\n",
      "2\n",
      "358GB\n",
      "$18.50\n",
      "4\n",
      "716GB\n",
      "$37.00\n",
      "8\n",
      "1432GB\n",
      "$74.00\n",
      "gcp\n",
      "NVIDIA T4\n",
      "1\n",
      "16GB\n",
      "$0.50\n",
      "gcp\n",
      "NVIDIA L4\n",
      "1\n",
      "24GB\n",
      "$0.70\n",
      "4\n",
      "96GB\n",
      "$3.80\n",
      "gcp\n",
      "NVIDIA A100\n",
      "1\n",
      "80GB\n",
      "$3.60\n",
      "2\n",
      "160GB\n",
      "$7.20\n",
      "4\n",
      "320GB\n",
      "$14.40\n",
      "8\n",
      "640GB\n",
      "$28.80\n",
      "gcp\n",
      "NVIDIA H100\n",
      "1\n",
      "80GB\n",
      "$10.00\n",
      "2\n",
      "160GB\n",
      "$20.00\n",
      "4\n",
      "320GB\n",
      "$40.00\n",
      "8\n",
      "640GB\n",
      "$80.00\n",
      "PRO Account\n",
      "PRO\n",
      "A monthly subscription to access powerful features.\n",
      "‚Üí\n",
      "Get PRO\n",
      "($9/month)\n",
      "Inference Providers\n",
      ": Get 20√ó included inference credits\n",
      "ZeroGPU\n",
      ": Get 8√ó usage quota and highest priority in queues\n",
      "Spaces Hosting\n",
      ": Create ZeroGPU Spaces with H200 hardware\n",
      "Spaces Dev Mode\n",
      ": Fast iterations via SSH/VS Code for Spaces\n",
      "Dataset Viewer\n",
      ": Activate and use it on private datasets\n",
      "Blog Articles\n",
      ": Publish articles on your HF profile\n",
      "Features Preview\n",
      ": Get early access to upcoming\n",
      "\t\t\t\t\t\t\t\t\t\tfeatures\n",
      "PRO\n",
      "Badge\n",
      ":\n",
      "\t\t\t\t\t\t\t\t\t\tShow your support on your profile\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Careers\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "careers page\n",
      "Webpage Title:\n",
      "Hugging Face - Current Openings\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "docs page\n",
      "Webpage Title:\n",
      "Hugging Face - Documentation\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Documentation\n",
      "Hub & Client Libraries\n",
      "Hub\n",
      "Host Git-based models, datasets, and Spaces on the HF Hub\n",
      "Hub Python Library\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Huggingface.js\n",
      "JavaScript libraries for Hugging Face with built-in TS types\n",
      "Tasks\n",
      "Explore demos, models, and datasets for any ML tasks\n",
      "Dataset viewer\n",
      "API for metadata, stats, and content of HF Hub datasets\n",
      "Deployment & Inference\n",
      "Inference Providers\n",
      "Call 200k+ models hosted by our 10+ Inference partners\n",
      "Inference Endpoints (dedicated)\n",
      "Deploy models on dedicated & fully managed infrastructure on HF\n",
      "Deploying on AWS\n",
      "Train/deploy models from Hugging Face to AWS with DLCs\n",
      "Text Generation Inference\n",
      "Serve language models with TGI optimized toolkit\n",
      "Text Embeddings Inference\n",
      "Serve embeddings models with TEI optimized toolkit\n",
      "Microsoft Azure\n",
      "Deploy Hugging Face models on Microsoft Azure\n",
      "Google Cloud\n",
      "Train and Deploy Hugging Face models on Google Cloud\n",
      "Core ML Libraries\n",
      "Transformers\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Datasets\n",
      "Access & share datasets for any ML tasks\n",
      "Transformers.js\n",
      "State-of-the-art ML running directly in your browser\n",
      "Tokenizers\n",
      "Fast tokenizers optimized for research & production\n",
      "Evaluate\n",
      "Evaluate and compare models performance\n",
      "timm\n",
      "State-of-the-art vision models: layers, optimizers, and utilities\n",
      "Sentence Transformers\n",
      "Embeddings, Retrieval, and Reranking\n",
      "Kernels\n",
      "Load and run compute kernels from the Hugging Face Hub\n",
      "Training & Optimization\n",
      "PEFT\n",
      "Parameter-efficient finetuning for large language models\n",
      "Accelerate\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "Optimum\n",
      "Optimize HF Transformers for faster training/inference\n",
      "AWS Trainium & Inferentia\n",
      "Train/deploy Transformers/Diffusers on AWS\n",
      "Google TPUs\n",
      "Train and Deploy models on Google TPUs via Optimum.\n",
      "TRL\n",
      "Train transformers LMs with reinforcement learning\n",
      "Safetensors\n",
      "Safe way to store/distribute neural network weights\n",
      "Bitsandbytes\n",
      "Optimize and quantize models with bitsandbytes\n",
      "Lighteval\n",
      "All-in-one toolkit to evaluate LLMs across multiple backends\n",
      "Collaboration & Extras\n",
      "Gradio\n",
      "Build ML demos and web apps with a few lines of Python\n",
      "Trackio\n",
      "A lightweight, local-first, and free experiment tracking Python library\n",
      "smolagents\n",
      "Smol library to build great agents in Python\n",
      "LeRobot\n",
      "Making AI for Robotics more accessible with end-to-end learning\n",
      "AutoTrain\n",
      "AutoTrain API and UI for seamless model training\n",
      "Chat UI\n",
      "Open source chat frontend powering HuggingChat\n",
      "Leaderboards\n",
      "Create custom Leaderboards on Hugging Face\n",
      "Argilla\n",
      "Collaboration tool for building high-quality datasets\n",
      "Distilabel\n",
      "Framework for synthetic data generation and AI feedback\n",
      "Community\n",
      "Blog\n",
      "Learn\n",
      "Discord\n",
      "Forum\n",
      "GitHub\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Careers\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "brand page\n",
      "Webpage Title:\n",
      "Brand assets - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Hugging Face ¬∑ Brand assets\n",
      "HF Logos\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      "HF Colors\n",
      "#FFD21E\n",
      "#FF9D00\n",
      "#6B7280\n",
      "HF Bio\n",
      "Hugging Face is the collaboration platform for the machine learning community.\n",
      "\n",
      "The Hugging Face Hub works as a central place where anyone can share, explore, discover, and experiment with open-source ML. HF empowers the next generation of machine learning engineers, scientists, and end users to learn, collaborate and share their work to build an open and ethical AI future together.\n",
      "\n",
      "With the fast-growing community, some of the most used open-source ML libraries and tools, and a talented science team exploring the edge of tech, Hugging Face is at the heart of the AI revolution.\n",
      "Copy to clipboard\n",
      "HF Universe\n",
      "Find other assets available for use from the Hugging Face brand universe\n",
      "here\n",
      ".\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Careers\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "learn page\n",
      "Webpage Title:\n",
      "Hugging Face - Learn\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Learn\n",
      "LLM Course\n",
      "This course will teach you about large language models using libraries from the HF ecosystem\n",
      "Robotics Course\n",
      "This course will teach you to build robots with using LeRobot\n",
      "MCP Course\n",
      "This course will teach you about Model Context Protocol\n",
      "a smol course\n",
      "This smollest course on post-training AI models\n",
      "Agents Course\n",
      "Learn to build and deploy your own AI agents\n",
      "Deep RL Course\n",
      "This course will teach you about deep reinforcement learning using libraries from the HF ecosystem\n",
      "Community Computer Vision Course\n",
      "This course will teach you about computer vision ML using libraries and models from the HF ecosystem\n",
      "Audio Course\n",
      "Learn to apply transformers to audio data using libraries from the HF ecosystem\n",
      "Open-Source AI Cookbook\n",
      "A collection of open-source-powered notebooks by AI builders, for AI builders\n",
      "ML for Games Course\n",
      "This course will teach you about integrating AI models your game and using AI tools in your game development workflow\n",
      "Diffusion Course\n",
      "Learn about diffusion models & how to use them with diffusers\n",
      "ML for 3D Course\n",
      "Learn about 3D ML with libraries from the HF ecosystem\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Careers\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "blog\n",
      "Webpage Title:\n",
      "Hugging Face ‚Äì Blog\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Community Blog & Articles\n",
      "New Article\n",
      "community\n",
      "guide\n",
      "open source collab\n",
      "partnerships\n",
      "research\n",
      "NLP\n",
      "Audio\n",
      "CV\n",
      "RL\n",
      "ethics\n",
      "Diffusion\n",
      "Game Development\n",
      "RLHF\n",
      "Leaderboard\n",
      "Case Studies\n",
      "LeRobot\n",
      "Inference Providers\n",
      "Community Articles\n",
      "view all\n",
      "Tensor Parallelism (TP) in Transformers: 5 Minutes to Understand\n",
      "8 days ago\n",
      "‚Ä¢\n",
      "60\n",
      "How We Use Claude Code Skills to Run 1,000+ ML Experiments a Day\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "25\n",
      "TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "18\n",
      "Make and publish your Reachy Mini App\n",
      "8 days ago\n",
      "‚Ä¢\n",
      "8\n",
      "I Built a RAG System That Listens to Live BBC News and Answers Questions About \"What Happened 10 Minutes Ago\"\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "8\n",
      "Ellora: Enhancing LLMs with LoRA - Standardized Recipes for Capability Enhancement\n",
      "9 days ago\n",
      "‚Ä¢\n",
      "11\n",
      "AI Energy Score v2: Refreshed Leaderboard, now with Reasoning üß†\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "9\n",
      "Muon vs MuonClip vs Muon+AdamW for Fine-Tuning\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "7\n",
      "üõ°Ô∏è Nemotron PII: Synthesized Data for Privacy-Preserving AI\n",
      "Oct 28\n",
      "‚Ä¢\n",
      "31\n",
      "Making Model Tuning Accessible: This is what we built observing 100s of users tune models!\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "6\n",
      "KV Caching Explained: Optimizing Transformer Inference Efficiency\n",
      "Jan 30\n",
      "‚Ä¢\n",
      "193\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "Feb 7\n",
      "‚Ä¢\n",
      "256\n",
      "The 1 Billion Token Challenge: Finding the Perfect Pre-training Mix\n",
      "Nov 3\n",
      "‚Ä¢\n",
      "51\n",
      "**An Edge-First Generalized LLM LoRA Fine-Tuning Framework for Heterogeneous GPUs**\n",
      "10 days ago\n",
      "‚Ä¢\n",
      "16\n",
      "Norm-Preserving Biprojected Abliteration\n",
      "Nov 6\n",
      "‚Ä¢\n",
      "52\n",
      "Code a simple RAG from scratch\n",
      "Oct 29, 2024\n",
      "‚Ä¢\n",
      "264\n",
      "Small Language Models (SLM): A Comprehensive Overview\n",
      "Feb 22\n",
      "‚Ä¢\n",
      "110\n",
      "Build Hallucination-Free RAG with Verbatim\n",
      "23 days ago\n",
      "‚Ä¢\n",
      "7\n",
      "From GRPO to DAPO and GSPO: What, Why, and How\n",
      "Aug 9\n",
      "‚Ä¢\n",
      "67\n",
      "Model statistics of the 50 most downloaded entities on Hugging Face\n",
      "Oct 13\n",
      "‚Ä¢\n",
      "36\n",
      "New in llama.cpp: Model Management\n",
      "35\n",
      "December 11, 2025\n",
      "llm\n",
      "fine-tuning\n",
      "open-source\n",
      "Codex is Open Sourcing AI models\n",
      "3\n",
      "December 11, 2025\n",
      "Apriel-1.6-15b-Thinker: Cost-efficient Frontier Multimodal Performance\n",
      "64\n",
      "December 9, 2025\n",
      "swift\n",
      "hub\n",
      "open-source\n",
      "Introducing swift-huggingface: The Complete Swift Client for Hugging Face\n",
      "28\n",
      "December 5, 2025\n",
      "llm\n",
      "reasoning\n",
      "agents\n",
      "DeepMath: A lightweight math reasoning Agent with smolagents\n",
      "26\n",
      "December 4, 2025\n",
      "llm\n",
      "fine-tuning\n",
      "open-source\n",
      "We Got Claude to Fine-Tune an Open Source LLM\n",
      "458\n",
      "December 4, 2025\n",
      "Custom Policy Enforcement with Reasoning: Faster, Safer AI Applications\n",
      "21\n",
      "December 2, 2025\n",
      "transformers\n",
      "v5\n",
      "community\n",
      "Transformers v5: Simple model definitions powering the AI ecosystem\n",
      "234\n",
      "December 1, 2025\n",
      "diffusers\n",
      "flux\n",
      "quantization\n",
      "Diffusers welcomes FLUX-2\n",
      "+4\n",
      "161\n",
      "November 25, 2025\n",
      "transformers\n",
      "pytorch\n",
      "optimization\n",
      "Continuous batching from first principles\n",
      "266\n",
      "November 25, 2025\n",
      "Building Deep Research: How we Achieved State of the Art\n",
      "22\n",
      "November 24, 2025\n",
      "OVHcloud on Hugging Face Inference Providers üî•\n",
      "69\n",
      "November 24, 2025\n",
      "llm\n",
      "experimentation\n",
      "fine-tuning\n",
      "20x Faster TRL Fine-tuning with RapidFire AI\n",
      "24\n",
      "November 21, 2025\n",
      "audio\n",
      "speech\n",
      "leaderboard\n",
      "Open ASR Leaderboard: Trends and Insights with New Multilingual & Long-Form Tracks\n",
      "22\n",
      "November 21, 2025\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "51\n",
      "Next\n",
      "Community Articles\n",
      "Sort:¬†\n",
      "\t\tTrending\n",
      "NEW\n",
      "Articles from\n",
      "Team\n",
      "or\n",
      "Enterprise\n",
      "organizations will get promoted to the main section.\n",
      "Tensor Parallelism (TP) in Transformers: 5 Minutes to Understand\n",
      "8 days ago\n",
      "‚Ä¢\n",
      "60\n",
      "How We Use Claude Code Skills to Run 1,000+ ML Experiments a Day\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "25\n",
      "TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "18\n",
      "Make and publish your Reachy Mini App\n",
      "8 days ago\n",
      "‚Ä¢\n",
      "8\n",
      "I Built a RAG System That Listens to Live BBC News and Answers Questions About \"What Happened 10 Minutes Ago\"\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "8\n",
      "Ellora: Enhancing LLMs with LoRA - Standardized Recipes for Capability Enhancement\n",
      "9 days ago\n",
      "‚Ä¢\n",
      "11\n",
      "AI Energy Score v2: Refreshed Leaderboard, now with Reasoning üß†\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "9\n",
      "Muon vs MuonClip vs Muon+AdamW for Fine-Tuning\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "7\n",
      "üõ°Ô∏è Nemotron PII: Synthesized Data for Privacy-Preserving AI\n",
      "Oct 28\n",
      "‚Ä¢\n",
      "31\n",
      "Making Model Tuning Accessible: This is what we built observing 100s of users tune models!\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "6\n",
      "KV Caching Explained: Optimizing Transformer Inference Efficiency\n",
      "Jan 30\n",
      "‚Ä¢\n",
      "193\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "Feb 7\n",
      "‚Ä¢\n",
      "256\n",
      "The 1 Billion Token Challenge: Finding the Perfect Pre-training Mix\n",
      "Nov 3\n",
      "‚Ä¢\n",
      "51\n",
      "**An Edge-First Generalized LLM LoRA Fine-Tuning Framework for Heterogeneous GPUs**\n",
      "10 days ago\n",
      "‚Ä¢\n",
      "16\n",
      "Norm-Preserving Biprojected Abliteration\n",
      "Nov 6\n",
      "‚Ä¢\n",
      "52\n",
      "Code a simple RAG from scratch\n",
      "Oct 29, 2024\n",
      "‚Ä¢\n",
      "264\n",
      "Small Language Models (SLM): A Comprehensive Overview\n",
      "Feb 22\n",
      "‚Ä¢\n",
      "110\n",
      "Build Hallucination-Free RAG with Verbatim\n",
      "23 days ago\n",
      "‚Ä¢\n",
      "7\n",
      "From GRPO to DAPO and GSPO: What, Why, and How\n",
      "Aug 9\n",
      "‚Ä¢\n",
      "67\n",
      "Model statistics of the 50 most downloaded entities on Hugging Face\n",
      "Oct 13\n",
      "‚Ä¢\n",
      "36\n",
      "View all articles\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Careers\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "community forum\n",
      "Webpage Title:\n",
      "Hugging Face Forums - Hugging Face Community Discussion\n",
      "Webpage Contents:\n",
      "Hugging Face Forums\n",
      "Topic\n",
      "Replies\n",
      "Views\n",
      "Activity\n",
      "Benchmarked nanoGPT training costs across A100, H100, and RTX6000. A100 was ~2x more efficient than H100\n",
      "Research\n",
      "0\n",
      "9\n",
      "December 11, 2025\n",
      ":<|im_end|>\\n<|im_start|>assistant generated despite predict model used\n",
      "Intermediate\n",
      "3\n",
      "7\n",
      "December 11, 2025\n",
      "Do AI models feel?\n",
      "Research\n",
      "58\n",
      "389\n",
      "December 11, 2025\n",
      "Welche AI und zu welchem Preis?\n",
      "Beginners\n",
      "1\n",
      "10\n",
      "December 11, 2025\n",
      "How to add GB10 into NVIDIA hardware list in https://huggingface.co/settings/local-apps\n",
      "Site Feedback\n",
      "1\n",
      "10\n",
      "December 11, 2025\n",
      "Gerbil: An open source desktop app for running LLMs locally\n",
      "Show and Tell\n",
      "0\n",
      "15\n",
      "December 11, 2025\n",
      "[Pipelines] Mask Generation Parameters\n",
      "ü§óTransformers\n",
      "2\n",
      "28\n",
      "December 10, 2025\n",
      "Line messager show \"A timeout occurred when sending a webhook event object\" error\n",
      "Spaces\n",
      "3\n",
      "76\n",
      "December 11, 2025\n",
      "Hugging Chat pro\n",
      "Beginners\n",
      "1\n",
      "13\n",
      "December 11, 2025\n",
      "Transformers.js need for token to char mapping\n",
      "ü§óTransformers\n",
      "3\n",
      "12\n",
      "December 11, 2025\n",
      "Gameplay-Vision-LLM (open-source): long-horizon gameplay video understanding + causal reasoning ‚Äî can you review it and rate it 1‚Äì10?\n",
      "Show and Tell\n",
      "6\n",
      "30\n",
      "December 10, 2025\n",
      "Passkey authentication\n",
      "Site Feedback\n",
      "2\n",
      "36\n",
      "December 11, 2025\n",
      "Artificial intelligence\n",
      "Beginners\n",
      "4\n",
      "97\n",
      "December 11, 2025\n",
      "Space restart failed\n",
      "Beginners\n",
      "3\n",
      "15\n",
      "December 11, 2025\n",
      "HF transformers config issue for Mistral-Large-3 models\n",
      "Beginners\n",
      "5\n",
      "16\n",
      "December 11, 2025\n",
      "Struggling to install huggingface_hub\n",
      "Beginners\n",
      "14\n",
      "179\n",
      "December 11, 2025\n",
      "Enable AutoTrain on my PRO account\n",
      "ü§óAutoTrain\n",
      "2\n",
      "15\n",
      "December 9, 2025\n",
      "Spaces Persistent Storage Upgrade Not Accessible\n",
      "Spaces\n",
      "6\n",
      "48\n",
      "December 7, 2025\n",
      "Having trouble to configure trainer for T5 model evaluation\n",
      "ü§óTransformers\n",
      "1\n",
      "17\n",
      "December 9, 2025\n",
      "Langchain huggingface endpoints error\n",
      "Beginners\n",
      "3\n",
      "25\n",
      "December 9, 2025\n",
      "A Bidirectional LLM Firewall: Architecture, Failure Modes, and Evaluation Results\n",
      "Research\n",
      "12\n",
      "48\n",
      "December 12, 2025\n",
      "Early-Stage Idea: A Cognitive Architecture Built on Attention and Graph Traversal\n",
      "Show and Tell\n",
      "4\n",
      "55\n",
      "December 6, 2025\n",
      "Local Model Backups\n",
      "Beginners\n",
      "11\n",
      "61\n",
      "December 7, 2025\n",
      "How do I speedup my callbacks and reduce stall before they start?\n",
      "ü§óTransformers\n",
      "1\n",
      "17\n",
      "December 9, 2025\n",
      "Looking for arXiv cs.AI endorser ‚Äì independent researcher\n",
      "Research\n",
      "6\n",
      "207\n",
      "December 10, 2025\n",
      "Fine-tune a minimal LLM model with RTX 2050 GPU\n",
      "Beginners\n",
      "16\n",
      "101\n",
      "December 7, 2025\n",
      "Request to unlock mwtuni/avatar-mcp space\n",
      "Spaces\n",
      "2\n",
      "22\n",
      "December 7, 2025\n",
      "How to work with Huggingface with the xAI (Grok) API access?\n",
      "Beginners\n",
      "2\n",
      "71\n",
      "December 7, 2025\n",
      "Can't Upload arXiv Paper to HuggingFace Daily Papers\n",
      "ü§óHub\n",
      "13\n",
      "73\n",
      "December 3, 2025\n",
      "Feature request: date range filter in model search\n",
      "Site Feedback\n",
      "4\n",
      "28\n",
      "December 8, 2025\n",
      "next page ‚Üí\n",
      "Home\n",
      "Categories\n",
      "Guidelines\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Powered by\n",
      "Discourse\n",
      ", best viewed with JavaScript enabled\n",
      "\n",
      "\n",
      "\n",
      "status page\n",
      "Webpage Title:\n",
      "\n",
      "Hugging Face status\n",
      "\n",
      "Webpage Contents:\n",
      "Status\n",
      "Maintenance\n",
      "Previous incidents\n",
      "Get updates\n",
      "Get status updates\n",
      "E-mail\n",
      "RSS\n",
      "JSON\n",
      "Webhook\n",
      "Get e-mail notifications whenever Hugging Face creates, updates or resolves an incident.\n",
      "Subscribe to specific components\n",
      "Current status by service\n",
      "Huggingface Hub\n",
      "Git Hosting and Serving\n",
      "Inference Endpoints\n",
      "Inference Endpoints UI\n",
      "Inference Endpoints API\n",
      "Spaces\n",
      "Spaces Proxy\n",
      "Subscribe\n",
      "Get the RSS feed\n",
      "Get the entire status page as JSON\n",
      "Get a request to your URL whenever Hugging Face creates, updates or resolves an incident.\n",
      "We'll email you with confirmation and when there's an issue with your URL\n",
      "Subscribe to specific components\n",
      "Current status by service\n",
      "Huggingface Hub\n",
      "Git Hosting and Serving\n",
      "Inference Endpoints\n",
      "Inference Endpoints UI\n",
      "Inference Endpoints API\n",
      "Spaces\n",
      "Spaces Proxy\n",
      "Subscribe\n",
      "All services are online\n",
      "Last updated on Dec 11 at 08:32pm EST\n",
      "Current status by service\n",
      "Operational\n",
      "Huggingface Hub\n",
      "huggingface.co\n",
      "100.000% uptime\n",
      "Operational\n",
      "Sep 13, 2025\n",
      "Operational\n",
      "Sep 14, 2025\n",
      "Operational\n",
      "Sep 15, 2025\n",
      "Operational\n",
      "Sep 16, 2025\n",
      "Operational\n",
      "Sep 17, 2025\n",
      "Operational\n",
      "Sep 18, 2025\n",
      "Operational\n",
      "Sep 19, 2025\n",
      "Operational\n",
      "Sep 20, 2025\n",
      "Operational\n",
      "Sep 21, 2025\n",
      "Operational\n",
      "Sep 22, 2025\n",
      "Operational\n",
      "Sep 23, 2025\n",
      "Operational\n",
      "Sep 24, 2025\n",
      "Operational\n",
      "Sep 25, 2025\n",
      "Operational\n",
      "Sep 26, 2025\n",
      "Operational\n",
      "Sep 27, 2025\n",
      "Operational\n",
      "Sep 28, 2025\n",
      "Operational\n",
      "Sep 29, 2025\n",
      "Operational\n",
      "Sep 30, 2025\n",
      "Operational\n",
      "Oct 01, 2025\n",
      "Operational\n",
      "Oct 02, 2025\n",
      "Operational\n",
      "Oct 03, 2025\n",
      "Operational\n",
      "Oct 04, 2025\n",
      "Operational\n",
      "Oct 05, 2025\n",
      "Operational\n",
      "Oct 06, 2025\n",
      "Operational\n",
      "Oct 07, 2025\n",
      "Operational\n",
      "Oct 08, 2025\n",
      "Operational\n",
      "Oct 09, 2025\n",
      "Operational\n",
      "Oct 10, 2025\n",
      "Operational\n",
      "Oct 11, 2025\n",
      "Operational\n",
      "Oct 12, 2025\n",
      "Operational\n",
      "Oct 13, 2025\n",
      "Operational\n",
      "Oct 14, 2025\n",
      "Operational\n",
      "Oct 15, 2025\n",
      "Operational\n",
      "Oct 16, 2025\n",
      "Operational\n",
      "Oct 17, 2025\n",
      "Operational\n",
      "Oct 18, 2025\n",
      "Operational\n",
      "Oct 19, 2025\n",
      "Operational\n",
      "Oct 20, 2025\n",
      "Operational\n",
      "Oct 21, 2025\n",
      "Operational\n",
      "Oct 22, 2025\n",
      "Operational\n",
      "Oct 23, 2025\n",
      "Operational\n",
      "Oct 24, 2025\n",
      "Operational\n",
      "Oct 25, 2025\n",
      "Operational\n",
      "Oct 26, 2025\n",
      "Operational\n",
      "Oct 27, 2025\n",
      "Operational\n",
      "Oct 28, 2025\n",
      "Operational\n",
      "Oct 29, 2025\n",
      "Operational\n",
      "Oct 30, 2025\n",
      "Operational\n",
      "Oct 31, 2025\n",
      "Operational\n",
      "Nov 01, 2025\n",
      "Operational\n",
      "Nov 02, 2025\n",
      "Operational\n",
      "Nov 03, 2025\n",
      "Operational\n",
      "Nov 04, 2025\n",
      "Operational\n",
      "Nov 05, 2025\n",
      "Operational\n",
      "Nov 06, 2025\n",
      "Operational\n",
      "Nov 07, 2025\n",
      "Operational\n",
      "Nov 08, 2025\n",
      "Operational\n",
      "Nov 09, 2025\n",
      "Operational\n",
      "Nov 10, 2025\n",
      "Operational\n",
      "Nov 11, 2025\n",
      "Operational\n",
      "Nov 12, 2025\n",
      "Operational\n",
      "Nov 13, 2025\n",
      "Operational\n",
      "Nov 14, 2025\n",
      "Operational\n",
      "Nov 15, 2025\n",
      "Operational\n",
      "Nov 16, 2025\n",
      "Operational\n",
      "Nov 17, 2025\n",
      "Operational\n",
      "Nov 18, 2025\n",
      "Operational\n",
      "Nov 19, 2025\n",
      "Operational\n",
      "Nov 20, 2025\n",
      "Operational\n",
      "Nov 21, 2025\n",
      "Operational\n",
      "Nov 22, 2025\n",
      "Operational\n",
      "Nov 23, 2025\n",
      "Operational\n",
      "Nov 24, 2025\n",
      "Operational\n",
      "Nov 25, 2025\n",
      "Operational\n",
      "Nov 26, 2025\n",
      "Operational\n",
      "Nov 27, 2025\n",
      "Operational\n",
      "Nov 28, 2025\n",
      "Operational\n",
      "Nov 29, 2025\n",
      "Operational\n",
      "Nov 30, 2025\n",
      "Operational\n",
      "Dec 01, 2025\n",
      "Operational\n",
      "Dec 02, 2025\n",
      "Operational\n",
      "Dec 03, 2025\n",
      "Operational\n",
      "Dec 04, 2025\n",
      "Operational\n",
      "Dec 05, 2025\n",
      "Operational\n",
      "Dec 06, 2025\n",
      "Operational\n",
      "Dec 07, 2025\n",
      "Operational\n",
      "Dec 08, 2025\n",
      "Operational\n",
      "Dec 09, 2025\n",
      "Operational\n",
      "Dec 10, 2025\n",
      "Operational\n",
      "Dec 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Git Hosting and Serving\n",
      "Hugging Face Hub, git hosting of models and datasets\n",
      "99.992% uptime\n",
      "Operational\n",
      "Sep 13, 2025\n",
      "Operational\n",
      "Sep 14, 2025\n",
      "Operational\n",
      "Sep 15, 2025\n",
      "Operational\n",
      "Sep 16, 2025\n",
      "Operational\n",
      "Sep 17, 2025\n",
      "Operational\n",
      "Sep 18, 2025\n",
      "Operational\n",
      "Sep 19, 2025\n",
      "Operational\n",
      "Sep 20, 2025\n",
      "Operational\n",
      "Sep 21, 2025\n",
      "Operational\n",
      "Sep 22, 2025\n",
      "Downtime\n",
      "Down for 10¬†minutes\n",
      "Sep 23, 2025\n",
      "Operational\n",
      "Sep 24, 2025\n",
      "Operational\n",
      "Sep 25, 2025\n",
      "Operational\n",
      "Sep 26, 2025\n",
      "Operational\n",
      "Sep 27, 2025\n",
      "Operational\n",
      "Sep 28, 2025\n",
      "Operational\n",
      "Sep 29, 2025\n",
      "Operational\n",
      "Sep 30, 2025\n",
      "Operational\n",
      "Oct 01, 2025\n",
      "Operational\n",
      "Oct 02, 2025\n",
      "Operational\n",
      "Oct 03, 2025\n",
      "Operational\n",
      "Oct 04, 2025\n",
      "Operational\n",
      "Oct 05, 2025\n",
      "Operational\n",
      "Oct 06, 2025\n",
      "Operational\n",
      "Oct 07, 2025\n",
      "Operational\n",
      "Oct 08, 2025\n",
      "Operational\n",
      "Oct 09, 2025\n",
      "Operational\n",
      "Oct 10, 2025\n",
      "Operational\n",
      "Oct 11, 2025\n",
      "Operational\n",
      "Oct 12, 2025\n",
      "Operational\n",
      "Oct 13, 2025\n",
      "Operational\n",
      "Oct 14, 2025\n",
      "Operational\n",
      "Oct 15, 2025\n",
      "Operational\n",
      "Oct 16, 2025\n",
      "Operational\n",
      "Oct 17, 2025\n",
      "Operational\n",
      "Oct 18, 2025\n",
      "Operational\n",
      "Oct 19, 2025\n",
      "Operational\n",
      "Oct 20, 2025\n",
      "Operational\n",
      "Oct 21, 2025\n",
      "Operational\n",
      "Oct 22, 2025\n",
      "Operational\n",
      "Oct 23, 2025\n",
      "Operational\n",
      "Oct 24, 2025\n",
      "Operational\n",
      "Oct 25, 2025\n",
      "Operational\n",
      "Oct 26, 2025\n",
      "Operational\n",
      "Oct 27, 2025\n",
      "Operational\n",
      "Oct 28, 2025\n",
      "Operational\n",
      "Oct 29, 2025\n",
      "Operational\n",
      "Oct 30, 2025\n",
      "Operational\n",
      "Oct 31, 2025\n",
      "Operational\n",
      "Nov 01, 2025\n",
      "Operational\n",
      "Nov 02, 2025\n",
      "Operational\n",
      "Nov 03, 2025\n",
      "Operational\n",
      "Nov 04, 2025\n",
      "Operational\n",
      "Nov 05, 2025\n",
      "Operational\n",
      "Nov 06, 2025\n",
      "Operational\n",
      "Nov 07, 2025\n",
      "Operational\n",
      "Nov 08, 2025\n",
      "Operational\n",
      "Nov 09, 2025\n",
      "Operational\n",
      "Nov 10, 2025\n",
      "Operational\n",
      "Nov 11, 2025\n",
      "Operational\n",
      "Nov 12, 2025\n",
      "Operational\n",
      "Nov 13, 2025\n",
      "Operational\n",
      "Nov 14, 2025\n",
      "Operational\n",
      "Nov 15, 2025\n",
      "Operational\n",
      "Nov 16, 2025\n",
      "Operational\n",
      "Nov 17, 2025\n",
      "Operational\n",
      "Nov 18, 2025\n",
      "Operational\n",
      "Nov 19, 2025\n",
      "Operational\n",
      "Nov 20, 2025\n",
      "Operational\n",
      "Nov 21, 2025\n",
      "Operational\n",
      "Nov 22, 2025\n",
      "Operational\n",
      "Nov 23, 2025\n",
      "Operational\n",
      "Nov 24, 2025\n",
      "Operational\n",
      "Nov 25, 2025\n",
      "Operational\n",
      "Nov 26, 2025\n",
      "Operational\n",
      "Nov 27, 2025\n",
      "Operational\n",
      "Nov 28, 2025\n",
      "Operational\n",
      "Nov 29, 2025\n",
      "Operational\n",
      "Nov 30, 2025\n",
      "Operational\n",
      "Dec 01, 2025\n",
      "Operational\n",
      "Dec 02, 2025\n",
      "Operational\n",
      "Dec 03, 2025\n",
      "Operational\n",
      "Dec 04, 2025\n",
      "Operational\n",
      "Dec 05, 2025\n",
      "Operational\n",
      "Dec 06, 2025\n",
      "Operational\n",
      "Dec 07, 2025\n",
      "Operational\n",
      "Dec 08, 2025\n",
      "Operational\n",
      "Dec 09, 2025\n",
      "Operational\n",
      "Dec 10, 2025\n",
      "Operational\n",
      "Dec 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Inference Endpoints\n",
      "Operational\n",
      "Inference Endpoints UI\n",
      "99.977% uptime\n",
      "Operational\n",
      "Sep 13, 2025\n",
      "Operational\n",
      "Sep 14, 2025\n",
      "Operational\n",
      "Sep 15, 2025\n",
      "Operational\n",
      "Sep 16, 2025\n",
      "Operational\n",
      "Sep 17, 2025\n",
      "Operational\n",
      "Sep 18, 2025\n",
      "Operational\n",
      "Sep 19, 2025\n",
      "Operational\n",
      "Sep 20, 2025\n",
      "Operational\n",
      "Sep 21, 2025\n",
      "Operational\n",
      "Sep 22, 2025\n",
      "Operational\n",
      "Sep 23, 2025\n",
      "Operational\n",
      "Sep 24, 2025\n",
      "Operational\n",
      "Sep 25, 2025\n",
      "Operational\n",
      "Sep 26, 2025\n",
      "Operational\n",
      "Sep 27, 2025\n",
      "Operational\n",
      "Sep 28, 2025\n",
      "Operational\n",
      "Sep 29, 2025\n",
      "Operational\n",
      "Sep 30, 2025\n",
      "Operational\n",
      "Oct 01, 2025\n",
      "Operational\n",
      "Oct 02, 2025\n",
      "Operational\n",
      "Oct 03, 2025\n",
      "Operational\n",
      "Oct 04, 2025\n",
      "Operational\n",
      "Oct 05, 2025\n",
      "Operational\n",
      "Oct 06, 2025\n",
      "Operational\n",
      "Oct 07, 2025\n",
      "Operational\n",
      "Oct 08, 2025\n",
      "Operational\n",
      "Oct 09, 2025\n",
      "Operational\n",
      "Oct 10, 2025\n",
      "Operational\n",
      "Oct 11, 2025\n",
      "Operational\n",
      "Oct 12, 2025\n",
      "Operational\n",
      "Oct 13, 2025\n",
      "Operational\n",
      "Oct 14, 2025\n",
      "Operational\n",
      "Oct 15, 2025\n",
      "Operational\n",
      "Oct 16, 2025\n",
      "Operational\n",
      "Oct 17, 2025\n",
      "Operational\n",
      "Oct 18, 2025\n",
      "Operational\n",
      "Oct 19, 2025\n",
      "Downtime\n",
      "Down for 30¬†minutes\n",
      "Oct 20, 2025\n",
      "Operational\n",
      "Oct 21, 2025\n",
      "Operational\n",
      "Oct 22, 2025\n",
      "Operational\n",
      "Oct 23, 2025\n",
      "Operational\n",
      "Oct 24, 2025\n",
      "Operational\n",
      "Oct 25, 2025\n",
      "Operational\n",
      "Oct 26, 2025\n",
      "Operational\n",
      "Oct 27, 2025\n",
      "Operational\n",
      "Oct 28, 2025\n",
      "Operational\n",
      "Oct 29, 2025\n",
      "Operational\n",
      "Oct 30, 2025\n",
      "Operational\n",
      "Oct 31, 2025\n",
      "Operational\n",
      "Nov 01, 2025\n",
      "Operational\n",
      "Nov 02, 2025\n",
      "Operational\n",
      "Nov 03, 2025\n",
      "Operational\n",
      "Nov 04, 2025\n",
      "Operational\n",
      "Nov 05, 2025\n",
      "Operational\n",
      "Nov 06, 2025\n",
      "Operational\n",
      "Nov 07, 2025\n",
      "Operational\n",
      "Nov 08, 2025\n",
      "Operational\n",
      "Nov 09, 2025\n",
      "Operational\n",
      "Nov 10, 2025\n",
      "Operational\n",
      "Nov 11, 2025\n",
      "Operational\n",
      "Nov 12, 2025\n",
      "Operational\n",
      "Nov 13, 2025\n",
      "Operational\n",
      "Nov 14, 2025\n",
      "Operational\n",
      "Nov 15, 2025\n",
      "Operational\n",
      "Nov 16, 2025\n",
      "Operational\n",
      "Nov 17, 2025\n",
      "Operational\n",
      "Nov 18, 2025\n",
      "Operational\n",
      "Nov 19, 2025\n",
      "Operational\n",
      "Nov 20, 2025\n",
      "Operational\n",
      "Nov 21, 2025\n",
      "Operational\n",
      "Nov 22, 2025\n",
      "Operational\n",
      "Nov 23, 2025\n",
      "Operational\n",
      "Nov 24, 2025\n",
      "Operational\n",
      "Nov 25, 2025\n",
      "Operational\n",
      "Nov 26, 2025\n",
      "Operational\n",
      "Nov 27, 2025\n",
      "Operational\n",
      "Nov 28, 2025\n",
      "Operational\n",
      "Nov 29, 2025\n",
      "Operational\n",
      "Nov 30, 2025\n",
      "Operational\n",
      "Dec 01, 2025\n",
      "Operational\n",
      "Dec 02, 2025\n",
      "Operational\n",
      "Dec 03, 2025\n",
      "Operational\n",
      "Dec 04, 2025\n",
      "Operational\n",
      "Dec 05, 2025\n",
      "Operational\n",
      "Dec 06, 2025\n",
      "Operational\n",
      "Dec 07, 2025\n",
      "Operational\n",
      "Dec 08, 2025\n",
      "Operational\n",
      "Dec 09, 2025\n",
      "Operational\n",
      "Dec 10, 2025\n",
      "Operational\n",
      "Dec 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Inference Endpoints API\n",
      "100.000% uptime\n",
      "Operational\n",
      "Sep 13, 2025\n",
      "Operational\n",
      "Sep 14, 2025\n",
      "Operational\n",
      "Sep 15, 2025\n",
      "Operational\n",
      "Sep 16, 2025\n",
      "Operational\n",
      "Sep 17, 2025\n",
      "Operational\n",
      "Sep 18, 2025\n",
      "Operational\n",
      "Sep 19, 2025\n",
      "Operational\n",
      "Sep 20, 2025\n",
      "Operational\n",
      "Sep 21, 2025\n",
      "Operational\n",
      "Sep 22, 2025\n",
      "Operational\n",
      "Sep 23, 2025\n",
      "Operational\n",
      "Sep 24, 2025\n",
      "Operational\n",
      "Sep 25, 2025\n",
      "Operational\n",
      "Sep 26, 2025\n",
      "Operational\n",
      "Sep 27, 2025\n",
      "Operational\n",
      "Sep 28, 2025\n",
      "Operational\n",
      "Sep 29, 2025\n",
      "Operational\n",
      "Sep 30, 2025\n",
      "Operational\n",
      "Oct 01, 2025\n",
      "Operational\n",
      "Oct 02, 2025\n",
      "Operational\n",
      "Oct 03, 2025\n",
      "Operational\n",
      "Oct 04, 2025\n",
      "Operational\n",
      "Oct 05, 2025\n",
      "Operational\n",
      "Oct 06, 2025\n",
      "Operational\n",
      "Oct 07, 2025\n",
      "Operational\n",
      "Oct 08, 2025\n",
      "Operational\n",
      "Oct 09, 2025\n",
      "Operational\n",
      "Oct 10, 2025\n",
      "Operational\n",
      "Oct 11, 2025\n",
      "Operational\n",
      "Oct 12, 2025\n",
      "Operational\n",
      "Oct 13, 2025\n",
      "Operational\n",
      "Oct 14, 2025\n",
      "Operational\n",
      "Oct 15, 2025\n",
      "Operational\n",
      "Oct 16, 2025\n",
      "Operational\n",
      "Oct 17, 2025\n",
      "Operational\n",
      "Oct 18, 2025\n",
      "Operational\n",
      "Oct 19, 2025\n",
      "Operational\n",
      "Oct 20, 2025\n",
      "Operational\n",
      "Oct 21, 2025\n",
      "Operational\n",
      "Oct 22, 2025\n",
      "Operational\n",
      "Oct 23, 2025\n",
      "Operational\n",
      "Oct 24, 2025\n",
      "Operational\n",
      "Oct 25, 2025\n",
      "Operational\n",
      "Oct 26, 2025\n",
      "Operational\n",
      "Oct 27, 2025\n",
      "Operational\n",
      "Oct 28, 2025\n",
      "Operational\n",
      "Oct 29, 2025\n",
      "Operational\n",
      "Oct 30, 2025\n",
      "Operational\n",
      "Oct 31, 2025\n",
      "Operational\n",
      "Nov 01, 2025\n",
      "Operational\n",
      "Nov 02, 2025\n",
      "Operational\n",
      "Nov 03, 2025\n",
      "Operational\n",
      "Nov 04, 2025\n",
      "Operational\n",
      "Nov 05, 2025\n",
      "Operational\n",
      "Nov 06, 2025\n",
      "Operational\n",
      "Nov 07, 2025\n",
      "Operational\n",
      "Nov 08, 2025\n",
      "Operational\n",
      "Nov 09, 2025\n",
      "Operational\n",
      "Nov 10, 2025\n",
      "Operational\n",
      "Nov 11, 2025\n",
      "Operational\n",
      "Nov 12, 2025\n",
      "Operational\n",
      "Nov 13, 2025\n",
      "Operational\n",
      "Nov 14, 2025\n",
      "Operational\n",
      "Nov 15, 2025\n",
      "Operational\n",
      "Nov 16, 2025\n",
      "Operational\n",
      "Nov 17, 2025\n",
      "Operational\n",
      "Nov 18, 2025\n",
      "Operational\n",
      "Nov 19, 2025\n",
      "Operational\n",
      "Nov 20, 2025\n",
      "Operational\n",
      "Nov 21, 2025\n",
      "Operational\n",
      "Nov 22, 2025\n",
      "Operational\n",
      "Nov 23, 2025\n",
      "Operational\n",
      "Nov 24, 2025\n",
      "Operational\n",
      "Nov 25, 2025\n",
      "Operational\n",
      "Nov 26, 2025\n",
      "Operational\n",
      "Nov 27, 2025\n",
      "Operational\n",
      "Nov 28, 2025\n",
      "Operational\n",
      "Nov 29, 2025\n",
      "Operational\n",
      "Nov 30, 2025\n",
      "Operational\n",
      "Dec 01, 2025\n",
      "Operational\n",
      "Dec 02, 2025\n",
      "Operational\n",
      "Dec 03, 2025\n",
      "Operational\n",
      "Dec 04, 2025\n",
      "Operational\n",
      "Dec 05, 2025\n",
      "Operational\n",
      "Dec 06, 2025\n",
      "Operational\n",
      "Dec 07, 2025\n",
      "Operational\n",
      "Dec 08, 2025\n",
      "Operational\n",
      "Dec 09, 2025\n",
      "Operational\n",
      "Dec 10, 2025\n",
      "Operational\n",
      "Dec 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Spaces\n",
      "Operational\n",
      "Spaces Proxy\n",
      "99.935% uptime\n",
      "Operational\n",
      "Sep 13, 2025\n",
      "Operational\n",
      "Sep 14, 2025\n",
      "Operational\n",
      "Sep 15, 2025\n",
      "Operational\n",
      "Sep 16, 2025\n",
      "Operational\n",
      "Sep 17, 2025\n",
      "Operational\n",
      "Sep 18, 2025\n",
      "Operational\n",
      "Sep 19, 2025\n",
      "Operational\n",
      "Sep 20, 2025\n",
      "Operational\n",
      "Sep 21, 2025\n",
      "Operational\n",
      "Sep 22, 2025\n",
      "Operational\n",
      "Sep 23, 2025\n",
      "Operational\n",
      "Sep 24, 2025\n",
      "Operational\n",
      "Sep 25, 2025\n",
      "Operational\n",
      "Sep 26, 2025\n",
      "Operational\n",
      "Sep 27, 2025\n",
      "Operational\n",
      "Sep 28, 2025\n",
      "Operational\n",
      "Sep 29, 2025\n",
      "Operational\n",
      "Sep 30, 2025\n",
      "Operational\n",
      "Oct 01, 2025\n",
      "Operational\n",
      "Oct 02, 2025\n",
      "Operational\n",
      "Oct 03, 2025\n",
      "Operational\n",
      "Oct 04, 2025\n",
      "Operational\n",
      "Oct 05, 2025\n",
      "Operational\n",
      "Oct 06, 2025\n",
      "Operational\n",
      "Oct 07, 2025\n",
      "Operational\n",
      "Oct 08, 2025\n",
      "Operational\n",
      "Oct 09, 2025\n",
      "Operational\n",
      "Oct 10, 2025\n",
      "Operational\n",
      "Oct 11, 2025\n",
      "Operational\n",
      "Oct 12, 2025\n",
      "Operational\n",
      "Oct 13, 2025\n",
      "Operational\n",
      "Oct 14, 2025\n",
      "Operational\n",
      "Oct 15, 2025\n",
      "Operational\n",
      "Oct 16, 2025\n",
      "Operational\n",
      "Oct 17, 2025\n",
      "Operational\n",
      "Oct 18, 2025\n",
      "Operational\n",
      "Oct 19, 2025\n",
      "Operational\n",
      "Oct 20, 2025\n",
      "Operational\n",
      "Oct 21, 2025\n",
      "Operational\n",
      "Oct 22, 2025\n",
      "Operational\n",
      "Oct 23, 2025\n",
      "Operational\n",
      "Oct 24, 2025\n",
      "Operational\n",
      "Oct 25, 2025\n",
      "Operational\n",
      "Oct 26, 2025\n",
      "Operational\n",
      "Oct 27, 2025\n",
      "Operational\n",
      "Oct 28, 2025\n",
      "Operational\n",
      "Oct 29, 2025\n",
      "Operational\n",
      "Oct 30, 2025\n",
      "Operational\n",
      "Oct 31, 2025\n",
      "Operational\n",
      "Nov 01, 2025\n",
      "Operational\n",
      "Nov 02, 2025\n",
      "Operational\n",
      "Nov 03, 2025\n",
      "Operational\n",
      "Nov 04, 2025\n",
      "Operational\n",
      "Nov 05, 2025\n",
      "Operational\n",
      "Nov 06, 2025\n",
      "Operational\n",
      "Nov 07, 2025\n",
      "Operational\n",
      "Nov 08, 2025\n",
      "Operational\n",
      "Nov 09, 2025\n",
      "Operational\n",
      "Nov 10, 2025\n",
      "Operational\n",
      "Nov 11, 2025\n",
      "Operational\n",
      "Nov 12, 2025\n",
      "Operational\n",
      "Nov 13, 2025\n",
      "Operational\n",
      "Nov 14, 2025\n",
      "Operational\n",
      "Nov 15, 2025\n",
      "Operational\n",
      "Nov 16, 2025\n",
      "Operational\n",
      "Nov 17, 2025\n",
      "Operational\n",
      "Nov 18, 2025\n",
      "Operational\n",
      "Nov 19, 2025\n",
      "Operational\n",
      "Nov 20, 2025\n",
      "Operational\n",
      "Nov 21, 2025\n",
      "Operational\n",
      "Nov 22, 2025\n",
      "Operational\n",
      "Nov 23, 2025\n",
      "Operational\n",
      "Nov 24, 2025\n",
      "Downtime\n",
      "Down for 30¬†minutes\n",
      "Nov 25, 2025\n",
      "Downtime\n",
      "Down for 16¬†minutes\n",
      "Nov 26, 2025\n",
      "Operational\n",
      "Nov 27, 2025\n",
      "Operational\n",
      "Nov 28, 2025\n",
      "Downtime\n",
      "Down for 29¬†minutes\n",
      "Nov 29, 2025\n",
      "Operational\n",
      "Nov 30, 2025\n",
      "Downtime\n",
      "Down for 8¬†minutes\n",
      "Dec 01, 2025\n",
      "Operational\n",
      "Dec 02, 2025\n",
      "Operational\n",
      "Dec 03, 2025\n",
      "Operational\n",
      "Dec 04, 2025\n",
      "Operational\n",
      "Dec 05, 2025\n",
      "Operational\n",
      "Dec 06, 2025\n",
      "Operational\n",
      "Dec 07, 2025\n",
      "Operational\n",
      "Dec 08, 2025\n",
      "Operational\n",
      "Dec 09, 2025\n",
      "Operational\n",
      "Dec 10, 2025\n",
      "Operational\n",
      "Dec 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Powered by\n",
      "Better Stack\n",
      "\n",
      "\n",
      "\n",
      "GitHub page\n",
      "Webpage Title:\n",
      "Hugging Face ¬∑ GitHub\n",
      "Webpage Contents:\n",
      "Skip to content\n",
      "Navigation Menu\n",
      "Toggle navigation\n",
      "Sign in\n",
      "Appearance settings\n",
      "huggingface\n",
      "Platform\n",
      "AI CODE CREATION\n",
      "GitHub Copilot\n",
      "Write better code with AI\n",
      "GitHub Spark\n",
      "Build and deploy intelligent apps\n",
      "GitHub Models\n",
      "Manage and compare prompts\n",
      "MCP Registry\n",
      "New\n",
      "Integrate external tools\n",
      "DEVELOPER WORKFLOWS\n",
      "Actions\n",
      "Automate any workflow\n",
      "Codespaces\n",
      "Instant dev environments\n",
      "Issues\n",
      "Plan and track work\n",
      "Code Review\n",
      "Manage code changes\n",
      "APPLICATION SECURITY\n",
      "GitHub Advanced Security\n",
      "Find and fix vulnerabilities\n",
      "Code security\n",
      "Secure your code as you build\n",
      "Secret protection\n",
      "Stop leaks before they start\n",
      "EXPLORE\n",
      "Why GitHub\n",
      "Documentation\n",
      "Blog\n",
      "Changelog\n",
      "Marketplace\n",
      "View all features\n",
      "Solutions\n",
      "BY COMPANY SIZE\n",
      "Enterprises\n",
      "Small and medium teams\n",
      "Startups\n",
      "Nonprofits\n",
      "BY USE CASE\n",
      "App Modernization\n",
      "DevSecOps\n",
      "DevOps\n",
      "CI/CD\n",
      "View all use cases\n",
      "BY INDUSTRY\n",
      "Healthcare\n",
      "Financial services\n",
      "Manufacturing\n",
      "Government\n",
      "View all industries\n",
      "View all solutions\n",
      "Resources\n",
      "EXPLORE BY TOPIC\n",
      "AI\n",
      "Software Development\n",
      "DevOps\n",
      "Security\n",
      "View all topics\n",
      "EXPLORE BY TYPE\n",
      "Customer stories\n",
      "Events & webinars\n",
      "Ebooks & reports\n",
      "Business insights\n",
      "GitHub Skills\n",
      "SUPPORT & SERVICES\n",
      "Documentation\n",
      "Customer support\n",
      "Community forum\n",
      "Trust center\n",
      "Partners\n",
      "Open Source\n",
      "COMMUNITY\n",
      "GitHub Sponsors\n",
      "Fund open source developers\n",
      "PROGRAMS\n",
      "Security Lab\n",
      "Maintainer Community\n",
      "Accelerator\n",
      "Archive Program\n",
      "REPOSITORIES\n",
      "Topics\n",
      "Trending\n",
      "Collections\n",
      "Enterprise\n",
      "ENTERPRISE SOLUTIONS\n",
      "Enterprise platform\n",
      "AI-powered developer platform\n",
      "AVAILABLE ADD-ONS\n",
      "GitHub Advanced Security\n",
      "Enterprise-grade security features\n",
      "Copilot for Business\n",
      "Enterprise-grade AI features\n",
      "Premium Support\n",
      "Enterprise-grade 24/7 support\n",
      "Pricing\n",
      "Search or jump to...\n",
      "Search code, repositories, users, issues, pull requests...\n",
      "Search\n",
      "Clear\n",
      "Search syntax tips\n",
      "Provide feedback\n",
      "We read every piece of feedback, and take your input very seriously.\n",
      "Include my email address so I can be contacted\n",
      "Cancel\n",
      "Submit feedback\n",
      "Saved searches\n",
      "Use saved searches to filter your results more quickly\n",
      "Cancel\n",
      "Create saved search\n",
      "Sign in\n",
      "Sign up\n",
      "Appearance settings\n",
      "Resetting focus\n",
      "You signed in with another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You signed out in another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You switched accounts on another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "Dismiss alert\n",
      "Hugging Face\n",
      "The AI community building the future.\n",
      "Verified\n",
      "We've verified that the organization\n",
      "huggingface\n",
      "controls the domain:\n",
      "huggingface.co\n",
      "Learn more about verified organizations\n",
      "Sponsor\n",
      "56.8k\n",
      "followers\n",
      "NYC + Paris\n",
      "https://huggingface.co/\n",
      "X\n",
      "@huggingface\n",
      "Overview\n",
      "Repositories\n",
      "Projects\n",
      "Packages\n",
      "People\n",
      "Sponsoring\n",
      "4\n",
      "More\n",
      "Overview\n",
      "Repositories\n",
      "Projects\n",
      "Packages\n",
      "People\n",
      "Sponsoring\n",
      "Pinned\n",
      "Loading\n",
      "transformers\n",
      "transformers\n",
      "Public\n",
      "ü§ó Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training.\n",
      "Python\n",
      "154k\n",
      "31.4k\n",
      "diffusers\n",
      "diffusers\n",
      "Public\n",
      "ü§ó Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch.\n",
      "Python\n",
      "32k\n",
      "6.6k\n",
      "datasets\n",
      "datasets\n",
      "Public\n",
      "ü§ó The largest hub of ready-to-use datasets for AI models with fast, easy-to-use and efficient data manipulation tools\n",
      "Python\n",
      "21k\n",
      "3k\n",
      "peft\n",
      "peft\n",
      "Public\n",
      "ü§ó PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.\n",
      "Python\n",
      "20.3k\n",
      "2.1k\n",
      "accelerate\n",
      "accelerate\n",
      "Public\n",
      "üöÄ A simple way to launch, train, and use PyTorch models on almost any device and distributed configuration, automatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support\n",
      "Python\n",
      "9.4k\n",
      "1.2k\n",
      "optimum\n",
      "optimum\n",
      "Public\n",
      "üöÄ Accelerate inference and training of ü§ó Transformers, Diffusers, TIMM and Sentence Transformers with easy to use hardware optimization tools\n",
      "Python\n",
      "3.2k\n",
      "607\n",
      "Repositories\n",
      "Loading\n",
      "Type\n",
      "Select type\n",
      "Forks\n",
      "Archived\n",
      "Mirrors\n",
      "Templates\n",
      "Language\n",
      "Select language\n",
      "All\n",
      "C\n",
      "C#\n",
      "C++\n",
      "Cuda\n",
      "Dockerfile\n",
      "Go\n",
      "Handlebars\n",
      "HTML\n",
      "Java\n",
      "JavaScript\n",
      "Jupyter Notebook\n",
      "Kotlin\n",
      "Lua\n",
      "Makefile\n",
      "MDX\n",
      "Mustache\n",
      "Nix\n",
      "Python\n",
      "Ruby\n",
      "Rust\n",
      "Shell\n",
      "Smarty\n",
      "Svelte\n",
      "Swift\n",
      "TypeScript\n",
      "Sort\n",
      "Select order\n",
      "Last updated\n",
      "Name\n",
      "Stars\n",
      "Showing 10 of 376 repositories\n",
      "trl\n",
      "Public\n",
      "Train transformer language models with reinforcement learning.\n",
      "Uh oh!\n",
      "There was an error while loading.\n",
      "Please reload this page\n",
      ".\n",
      "huggingface/trl‚Äôs past year of commit activity\n",
      "Python\n",
      "16,615\n",
      "Apache-2.0\n",
      "2,349\n",
      "530\n",
      "78\n",
      "Updated\n",
      "Dec 12, 2025\n",
      "transformers.js\n",
      "Public\n",
      "State-of-the-art Machine Learning for the web. Run ü§ó Transformers directly in your browser, with no need for a server!\n",
      "huggingface/transformers.js‚Äôs past year of commit activity\n",
      "JavaScript\n",
      "15,074\n",
      "Apache-2.0\n",
      "1,051\n",
      "345\n",
      "(3 issues need help)\n",
      "75\n",
      "Updated\n",
      "Dec 12, 2025\n",
      "transformers\n",
      "Public\n",
      "ü§ó Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training.\n",
      "huggingface/transformers‚Äôs past year of commit activity\n",
      "Python\n",
      "153,757\n",
      "Apache-2.0\n",
      "31,395\n",
      "1,103\n",
      "(2 issues need help)\n",
      "1,059\n",
      "Updated\n",
      "Dec 11, 2025\n",
      "pytorch-image-models\n",
      "Public\n",
      "The largest collection of PyTorch image encoders / backbones. Including train, eval, inference, export scripts, and pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNetV4, MobileNet-V3 & V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more\n",
      "huggingface/pytorch-image-models‚Äôs past year of commit activity\n",
      "Python\n",
      "35,989\n",
      "Apache-2.0\n",
      "5,083\n",
      "55\n",
      "(3 issues need help)\n",
      "18\n",
      "Updated\n",
      "Dec 11, 2025\n",
      "hub-docs\n",
      "Public\n",
      "Docs of the Hugging Face Hub\n",
      "huggingface/hub-docs‚Äôs past year of commit activity\n",
      "Handlebars\n",
      "479\n",
      "Apache-2.0\n",
      "387\n",
      "126\n",
      "25\n",
      "Updated\n",
      "Dec 11, 2025\n",
      "optimum-executorch\n",
      "Public\n",
      "ü§ó Optimum ExecuTorch\n",
      "huggingface/optimum-executorch‚Äôs past year of commit activity\n",
      "Python\n",
      "89\n",
      "Apache-2.0\n",
      "29\n",
      "29\n",
      "(1 issue needs help)\n",
      "17\n",
      "Updated\n",
      "Dec 11, 2025\n",
      "xet-core\n",
      "Public\n",
      "xet client tech, used in huggingface_hub\n",
      "huggingface/xet-core‚Äôs past year of commit activity\n",
      "Rust\n",
      "351\n",
      "Apache-2.0\n",
      "43\n",
      "10\n",
      "15\n",
      "Updated\n",
      "Dec 11, 2025\n",
      "hf-endpoints-documentation\n",
      "Public\n",
      "huggingface/hf-endpoints-documentation‚Äôs past year of commit activity\n",
      "20\n",
      "16\n",
      "0\n",
      "0\n",
      "Updated\n",
      "Dec 12, 2025\n",
      "optimum-intel\n",
      "Public\n",
      "ü§ó Optimum Intel: Accelerate inference with Intel optimization tools\n",
      "huggingface/optimum-intel‚Äôs past year of commit activity\n",
      "Jupyter Notebook\n",
      "517\n",
      "Apache-2.0\n",
      "164\n",
      "39\n",
      "34\n",
      "Updated\n",
      "Dec 11, 2025\n",
      "kernel-builder\n",
      "Public\n",
      "üë∑ Build compute kernels\n",
      "huggingface/kernel-builder‚Äôs past year of commit activity\n",
      "Nix\n",
      "192\n",
      "30\n",
      "9\n",
      "2\n",
      "Updated\n",
      "Dec 11, 2025\n",
      "View all repositories\n",
      "People\n",
      "View all\n",
      "Sponsoring\n",
      "Top languages\n",
      "Python\n",
      "Jupyter Notebook\n",
      "TypeScript\n",
      "Rust\n",
      "MDX\n",
      "Most used topics\n",
      "pytorch\n",
      "machine-learning\n",
      "nlp\n",
      "transformers\n",
      "huggingface\n",
      "GitHub Sponsor\n",
      "Footer\n",
      "¬© 2025 GitHub,¬†Inc.\n",
      "Footer navigation\n",
      "Terms\n",
      "Privacy\n",
      "Security\n",
      "Status\n",
      "Community\n",
      "Docs\n",
      "Contact\n",
      "Manage cookies\n",
      "Do not share my personal information\n",
      "You can‚Äôt perform that action at this time.\n",
      "\n",
      "\n",
      "\n",
      "Twitter profile\n",
      "Webpage Title:\n",
      "No title found\n",
      "Webpage Contents:\n",
      "JavaScript is not available.\n",
      "We‚Äôve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.\n",
      "Help Center\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Imprint\n",
      "Ads info\n",
      "¬© 2025 X Corp.\n",
      "Something went wrong, but don‚Äôt fret ‚Äî let‚Äôs give it another shot.\n",
      "Try again\n",
      "Some privacy related extensions may cause issues on x.com. Please disable them and try again.\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn profile\n",
      "Webpage Title:\n",
      "Hugging Face | LinkedIn\n",
      "Webpage Contents:\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Top Content\n",
      "People\n",
      "Learning\n",
      "Jobs\n",
      "Games\n",
      "Get the app\n",
      "Sign in\n",
      "Create an account\n",
      "Hugging Face\n",
      "Software Development\n",
      "The AI community building the future.\n",
      "See jobs\n",
      "Follow\n",
      "Discover all 636 employees\n",
      "Report this company\n",
      "About us\n",
      "The AI community building the future.\n",
      "Website\n",
      "https://huggingface.co\n",
      "External link for Hugging Face\n",
      "Industry\n",
      "Software Development\n",
      "Company size\n",
      "51-200 employees\n",
      "Type\n",
      "Privately Held\n",
      "Founded\n",
      "2016\n",
      "Specialties\n",
      "machine learning, natural language processing, and deep learning\n",
      "Products\n",
      "Hugging Face\n",
      "Hugging Face\n",
      "Natural Language Processing (NLP) Software\n",
      "We‚Äôre on a journey to solve and democratize artificial intelligence through natural language.\n",
      "Locations\n",
      "Primary\n",
      "Get directions\n",
      "Paris, FR\n",
      "Get directions\n",
      "Employees at Hugging Face\n",
      "Ludovic Huraux\n",
      "Rajat Arya\n",
      "Jeff Boudier\n",
      "Terrence Rohan\n",
      "See all employees\n",
      "Updates\n",
      "Hugging Face\n",
      "reposted this\n",
      "Julien Chaumond\n",
      "9h\n",
      "Report this post\n",
      "llama.cpp\n",
      "CLI just got a massive makeover üî•\n",
      "\n",
      "> Clean looking interface\n",
      "> Multimodal support\n",
      "> Conversation control via commands\n",
      "> Speculative decoding support\n",
      "> Jinja fully supported\n",
      "\n",
      "great job\n",
      "Xuan-Son Nguyen\n",
      "Georgi Gerganov\n",
      "496\n",
      "10 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Merve Noyan\n",
      "9h\n",
      "Edited\n",
      "Report this post\n",
      "vibe train is here üöÇüòÑ\n",
      "you can ask Claude to fine-tune open vision language models in human terms: \"Fine-tune Qwen/Qwen3-VL-2B-Instruct on llava-instruct-mix\" ü§Ø\n",
      "\n",
      "thanks to HF Skills, it's a repo to do many things automagically using LLM of your choice ü™Ñ\n",
      "\n",
      "the `model-trainer` skill tells the LLM how to apply SFT, DPO, GRPO, and it uses\n",
      "Hugging Face\n",
      "Jobs to run the script on a GPU ü§ó\n",
      "\n",
      "read more here (it's only a few steps!):\n",
      "https://lnkd.in/d8s3HXwf\n",
      "few notes:\n",
      "> I managed to test this with vision language models thanks to native SFT support of TRL\n",
      "> native support for DPO and GRPO exists for LLMs and not VLMs, I will test on vision LMs shortly \n",
      "> Claude will ask you to make few changes, allow it\n",
      "318\n",
      "7 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Merve Noyan\n",
      "9h\n",
      "Edited\n",
      "Report this post\n",
      "vibe train is here üöÇüòÑ\n",
      "you can ask Claude to fine-tune open vision language models in human terms: \"Fine-tune Qwen/Qwen3-VL-2B-Instruct on llava-instruct-mix\" ü§Ø\n",
      "\n",
      "thanks to HF Skills, it's a repo to do many things automagically using LLM of your choice ü™Ñ\n",
      "\n",
      "the `model-trainer` skill tells the LLM how to apply SFT, DPO, GRPO, and it uses\n",
      "Hugging Face\n",
      "Jobs to run the script on a GPU ü§ó\n",
      "\n",
      "read more here (it's only a few steps!):\n",
      "https://lnkd.in/d8s3HXwf\n",
      "few notes:\n",
      "> I managed to test this with vision language models thanks to native SFT support of TRL\n",
      "> native support for DPO and GRPO exists for LLMs and not VLMs, I will test on vision LMs shortly \n",
      "> Claude will ask you to make few changes, allow it\n",
      "318\n",
      "7 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Google AI for Developers\n",
      "61,015 followers\n",
      "1d\n",
      "Edited\n",
      "Report this post\n",
      "üèÜ Introducing the winners of the Gemma 3n Impact Challenge on\n",
      "Kaggle\n",
      ":\n",
      "https://goo.gle/48MVqxx\n",
      "Explore how the global developer community built with Gemma to address critical challenges and make a difference in people‚Äôs lives through the potential of on-device, multimodal AI. ‚Üì\n",
      "\n",
      "ü•á First place: Vision assistant for the blind\n",
      "This AI assistant designed by Tommaso Giovannini\n",
      "¬†processes visuals from a phone camera when strapped to a body harness, enabling visually impaired users to navigate their surroundings with a voice-first interface.\n",
      "\n",
      "Second place: Vite Vere Offline\n",
      "This app helps users with cognitive disabilities navigate daily tasks. It integrates Gemma 3n to transform visual inputs into simple instructions that are then read aloud by a local text-to-speech engine powered by Flutter.\n",
      "\n",
      "Third place: 3VA\n",
      "Gemma 3n was fine-tuned to translate pictograms into rich expressions that reflect the user‚Äôs authentic voice. 3VA demonstrates how to develop personalized Augmentative and Alternative Communication tech at a fraction of the cost of traditional devices.\n",
      "\n",
      "Fourth place: Sixth Sense for Security Guards\n",
      "This video monitoring system by\n",
      "Abylay Ospan\n",
      "and Alsu Ospan combines movement detection with multimodal reasoning, using Gemma 3n to distinguish benign events from genuine threats.\n",
      "\n",
      "The\n",
      "Unsloth AI\n",
      "prize: Dream Assistant¬†\n",
      "This project uses the Unsloth library to train Gemma 3n on an individual‚Äôs voice recordings, resulting in a custom AI assistant that recognizes the user‚Äôs speech patterns and enables voice control over device functions.\n",
      "\n",
      "The\n",
      "Ollama\n",
      "prize: Lentera¬†\n",
      "Lentera is a platform to bring AI-powered resources to students and education in disconnected regions. This project transforms affordable hardware into offline microservers that run Gemma 3n via Ollama. \n",
      "\n",
      "The LeRobot prize: Graph-based Cost Learning and Gemma 3n for Sensing¬†\n",
      "This novel ‚Äúscanning-time-first‚Äù pipeline built on the LeRobot (a framework from\n",
      "Hugging Face\n",
      "addresses the major bottleneck of sensing time in robotic exploration. This approach shows the potential of Gemma 3n for autonomous search-and-rescue, inspection, and more.\n",
      "\n",
      "The\n",
      "NVIDIA\n",
      "Jetson Prize: Jetson offline voice AI\n",
      "This project deployed a context-aware voice interface on a\n",
      "NVIDIA\n",
      "Jetson to allow users of all ages to have responsive and context-aware voice conversations, while retaining privacy.\n",
      "311\n",
      "18 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Dana Aubakirova\n",
      "1d\n",
      "Edited\n",
      "Report this post\n",
      "ü§ñ Introducing LeRobot Community Dataset v3: The Crowdsourced Open-Source Multi-Embodiment Robotics Dataset\n",
      "\n",
      "We're excited to announce LeRobot Community Dataset v3 - a massive collaborative effort bringing together 235 contributors from around the world to advance vision-language-action learning in robotics.\n",
      "\n",
      "What's Inside:\n",
      "791 cleaned datasets across 46 different robot embodiments\n",
      "50,622 episodes bringing 250 hours of robot demonstrations\n",
      "26 million frames of multi-view robot manipulation data\n",
      "Single-arm, bimanual, mobile manipulation, and humanoid robots\n",
      "\n",
      "Highlights:\n",
      "ImageNet for Robotics? This is one of the largest open-source crowdsourced collections of robot demonstrations available. Think of it as embodied AI data at scale: diverse, real-world, and ready for cross-embodiment learning.\n",
      "\n",
      "Real diversity: From SO-100 arms to mobile manipulators and humanoids across 46 different platforms. Mix it with academic datasets and polished demonstrations to balance real-world variety with quality data.\n",
      "\n",
      "Cleaned and documented: We went from around 900 raw datasets to 791 ready ones through systematic debugging - handling missing videos, data type issues, and multi-camera standardization. Real-world, community-contributed data comes with challenges, and we've documented them in the dataset card :)\n",
      "\n",
      "Community-powered: 235 contributors worldwide made this possible. This is what open-source robotics collaboration looks like.\n",
      "\n",
      "ü§ó  Ready to train your next generalist robot policy? The data is waiting.\n",
      "‚Ä¶more\n",
      "133\n",
      "6 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Ben Burtenshaw\n",
      "1d\n",
      "Report this post\n",
      "Notebook for reinforcement learning on agents with custom knowledge bases. This uses a HUGE release for fine-tuning custom agents with TRL 0.26.0 and GRPO. \n",
      "\n",
      "In the notebook,\n",
      "- I set up an internal knowledge base agent with postgres for managing hotel bookings, and define python function tools that uses that the database.\n",
      "- I defined a simple dataset for user prompts like \"book a hotel\" or \"find hotels in Basel\"\n",
      "- I pass the tools to GRPOTrainer with a simple reward function.\n",
      "\n",
      "The main code is setting up a real knowledge base for hotel bookings, but it's a pretty cool example of a RAG agent. In the end, the model improve at it's tool use for hotel queries.\n",
      "\n",
      "Try  it out here:\n",
      "https://lnkd.in/edMPnRea\n",
      "476\n",
      "2 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Julien Chaumond\n",
      "4d\n",
      "Report this post\n",
      "We got Claude Code to train an open LLM ü§Ø\n",
      "\n",
      "Not just to write the training script, but to actually submit jobs to cloud GPUs, monitor progress, and push finished models to the Hugging Face Hub. \n",
      "\n",
      "Just say something like: \"Fine-tune Qwen3-0.6B on the dataset open-r1/codeforces-cots\"\n",
      "\n",
      "This is using Skills: packaged instructions, scripts, and domain knowledge, to accomplish specialized tasks:\n",
      "\n",
      "- You tell the agent to fine-tune a model on a dataset. You can define the dataset or let it search.\n",
      "- Agent picks hardware based on model size and checks dataset.\n",
      "- Job runs on cloud gpus. Either main run, or test run.\n",
      "- Agent share real-time progress dashboard with Trackio.\n",
      "- Checkpoints are pushed to HF.\n",
      "\n",
      "Check out the full tutorial ‚§µÔ∏è\n",
      "8,806\n",
      "265 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Jeff Boudier\n",
      "6d\n",
      "Report this post\n",
      "Can you make Claude reduce your Claude costs?\n",
      "\n",
      "Just came back from AWS re:Invent ; heard from multiple companies they got success building their own agents but each call costs $3-$5, due to ballooning tokens and Claude costs.\n",
      "\n",
      "The answer to driving costs down is open models. Open models to specialize a smaller LLM as the brain of the agentic system, and open models to build smarter tools that keep the context window under control.\n",
      "\n",
      "But what if you could use Claude to reduce your Claude agents costs?\n",
      "Ben Burtenshaw\n",
      "and\n",
      "Shaun Smith\n",
      "put out this brilliant step-by-step guide on how you can do exactly that - or any other LLM fine-tuning job using Claude, Gemini or Codex.\n",
      "\n",
      "tl;dr\n",
      "- Introducing Hugging Face Skills\n",
      "- Documenting hf-llm-trainer HF Skill\n",
      "- Supports SFT, DPO and GRPO out of the box\n",
      "- Works in Claude Code, OpenAI Codex, Google Gemini CLI\n",
      "- Uses serverless GPUs via Hugging Face Jobs (pay by the second)\n",
      "- Works in the background, with full monitoring using\n",
      "track.io\n",
      "OSS\n",
      "- Can convert to GGUF for on-device use cases\n",
      "\n",
      "Article in comments\n",
      "‚Ä¶more\n",
      "355\n",
      "17 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel Vila Suero\n",
      "6d\n",
      "Report this post\n",
      "I'm super excited to see evals becoming more native in the Hub ü§ó\n",
      "\n",
      "We just integrated the\n",
      "Hugging Face\n",
      "filesystem into Inspect AI, and honestly? It's wild that we've been paying AWS to share evaluation logs when the Hub exists.\n",
      "\n",
      "‚öôÔ∏è The entire flow:\n",
      "\n",
      "1. Run your eval, log to a HF dataset:\n",
      "\n",
      "inspect eval inspect_evals/bfcl \\\n",
      "  --model hf-inference-providers/moonshotai/Kimi-K2-Thinking \\\n",
      "  --log-dir hf://datasets/username/eval-logs \\\n",
      "  --log-shared \\\n",
      "  --log-buffer 100\n",
      "\n",
      "2. Watch results locally:\n",
      "\n",
      "inspect view --log-dir hf://datasets/username/eval-logs\n",
      "\n",
      "3. Or duplicate this Space to browse and share on the Hub:\n",
      "dvilasuero/inspect_viewer_template\n",
      "\n",
      "That's it. No S3 buckets, no access keys, no monthly AWS bills.\n",
      "\n",
      "‚ÅâÔ∏è Why this matters:\n",
      "\n",
      "- Free: HF datasets don't cost a cent. S3 adds up fast at scale\n",
      "- Open by default: Eval logs live where your models live. Reproducible, verifiable, forkable\n",
      "\n",
      "The eval ecosystem shouldn't run through a single cloud provider's billing system. \n",
      "\n",
      "Making evaluation as native to the Hub as model sharing feels like the obvious move.\n",
      "\n",
      "Works with the latest Inspect release. Give it a shot üöÄ\n",
      "\n",
      "See the first comment for a Space with eval results on the Hub\n",
      "112\n",
      "8 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Ben Burtenshaw\n",
      "1w\n",
      "Report this post\n",
      "We used Claude Code to train open LLMs! We plugged HF skills into claude code and it was able to train LLMs end-to-end. Best thing, this works on all major coding agents: Codex, Cursor, and Gemini CLI.\n",
      "\n",
      "üîó Deep dive blog\n",
      "https://lnkd.in/eX3UQqH9\n",
      "- You tell the agent to fine-tune a model on a dataset. You can define the dataset or let it search.\n",
      "- Agent picks hardware based on model size and checks dataset.\n",
      "- Job runs on cloud gpus. Either main run, or test run.\n",
      "- Agent share real-time progress dashboard with Trackio.\n",
      "- Checkpoints are pushed to the hub.\n",
      "\n",
      "Take it for a whirl now in your fav coding agent.\n",
      "2,804\n",
      "78 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Join now to see what you are missing\n",
      "Find people you know at Hugging Face\n",
      "Browse recommended jobs for you\n",
      "View all updates, news, and articles\n",
      "Join now\n",
      "Similar pages\n",
      "Anthropic\n",
      "Research Services\n",
      "Perplexity\n",
      "Software Development\n",
      "San Francisco, California\n",
      "Mistral AI\n",
      "Technology, Information and Internet\n",
      "Paris, France\n",
      "OpenAI\n",
      "Research Services\n",
      "San Francisco, CA\n",
      "LangChain\n",
      "Technology, Information and Internet\n",
      "Google DeepMind\n",
      "Research Services\n",
      "London, London\n",
      "DeepLearning.AI\n",
      "Software Development\n",
      "Mountain View, California\n",
      "Cohere\n",
      "Software Development\n",
      "Toronto, Ontario\n",
      "NVIDIA\n",
      "Computer Hardware Manufacturing\n",
      "Santa Clara, CA\n",
      "Google\n",
      "Software Development\n",
      "Mountain View, CA\n",
      "Show more similar pages\n",
      "Show fewer similar pages\n",
      "Browse jobs\n",
      "Engineer jobs\n",
      "555,845 open jobs\n",
      "Machine Learning Engineer jobs\n",
      "148,937 open jobs\n",
      "Scientist jobs\n",
      "48,969 open jobs\n",
      "Software Engineer jobs\n",
      "300,699 open jobs\n",
      "Analyst jobs\n",
      "694,057 open jobs\n",
      "Intern jobs\n",
      "71,196 open jobs\n",
      "Developer jobs\n",
      "258,935 open jobs\n",
      "Manager jobs\n",
      "1,880,925 open jobs\n",
      "Product Manager jobs\n",
      "199,941 open jobs\n",
      "Director jobs\n",
      "1,220,357 open jobs\n",
      "Python Developer jobs\n",
      "46,642 open jobs\n",
      "Data Scientist jobs\n",
      "264,158 open jobs\n",
      "Data Analyst jobs\n",
      "329,009 open jobs\n",
      "Senior Software Engineer jobs\n",
      "78,145 open jobs\n",
      "Project Manager jobs\n",
      "253,048 open jobs\n",
      "Researcher jobs\n",
      "195,654 open jobs\n",
      "Associate jobs\n",
      "1,091,945 open jobs\n",
      "Data Engineer jobs\n",
      "192,126 open jobs\n",
      "Vice President jobs\n",
      "235,270 open jobs\n",
      "Specialist jobs\n",
      "768,666 open jobs\n",
      "Show more jobs like this\n",
      "Show fewer jobs like this\n",
      "Funding\n",
      "Hugging Face\n",
      "8 total rounds\n",
      "Last Round\n",
      "Series unknown\n",
      "Sep 1, 2024\n",
      "External Crunchbase Link for last round of funding\n",
      "See more info on\n",
      "crunchbase\n",
      "More searches\n",
      "More searches\n",
      "Engineer jobs\n",
      "Scientist jobs\n",
      "Machine Learning Engineer jobs\n",
      "Software Engineer jobs\n",
      "Intern jobs\n",
      "Developer jobs\n",
      "Analyst jobs\n",
      "Manager jobs\n",
      "Senior Software Engineer jobs\n",
      "Data Scientist jobs\n",
      "Researcher jobs\n",
      "Product Manager jobs\n",
      "Director jobs\n",
      "Associate jobs\n",
      "Intelligence Specialist jobs\n",
      "Data Analyst jobs\n",
      "Data Science Specialist jobs\n",
      "Python Developer jobs\n",
      "Quantitative Analyst jobs\n",
      "Project Manager jobs\n",
      "Account Executive jobs\n",
      "Specialist jobs\n",
      "Data Engineer jobs\n",
      "Designer jobs\n",
      "Quantitative Researcher jobs\n",
      "Consultant jobs\n",
      "Solutions Architect jobs\n",
      "Vice President jobs\n",
      "User Experience Designer jobs\n",
      "Head jobs\n",
      "Full Stack Engineer jobs\n",
      "Engineering Manager jobs\n",
      "Software Engineer Intern jobs\n",
      "Junior Software Engineer jobs\n",
      "Software Intern jobs\n",
      "Product Designer jobs\n",
      "Solutions Engineer jobs\n",
      "Staff Software Engineer jobs\n",
      "Program Manager jobs\n",
      "Senior Scientist jobs\n",
      "Writer jobs\n",
      "Research Intern jobs\n",
      "Senior Product Manager jobs\n",
      "Summer Intern jobs\n",
      "Account Manager jobs\n",
      "Recruiter jobs\n",
      "Lead jobs\n",
      "Research Engineer jobs\n",
      "Computer Science Intern jobs\n",
      "Platform Engineer jobs\n",
      "Junior Developer jobs\n",
      "Android Developer jobs\n",
      "User Experience Researcher jobs\n",
      "Java Software Engineer jobs\n",
      "Site Reliability Engineer jobs\n",
      "Graduate jobs\n",
      "Software Engineering Manager jobs\n",
      "Representative jobs\n",
      "Business Development Specialist jobs\n",
      "Computer Engineer jobs\n",
      "LinkedIn\n",
      "¬© 2025\n",
      "About\n",
      "Accessibility\n",
      "User Agreement\n",
      "Privacy Policy\n",
      "Your California Privacy Choices\n",
      "Cookie Policy\n",
      "Copyright Policy\n",
      "Brand Policy\n",
      "Guest Controls\n",
      "Community Guidelines\n",
      "ÿßŸÑÿπÿ±ÿ®Ÿäÿ© (Arabic)\n",
      "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ (Bangla)\n",
      "ƒåe≈°tina (Czech)\n",
      "Dansk (Danish)\n",
      "Deutsch (German)\n",
      "ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ (Greek)\n",
      "English (English)\n",
      "Espa√±ol (Spanish)\n",
      "ŸÅÿßÿ±ÿ≥€å (Persian)\n",
      "Suomi (Finnish)\n",
      "Fran√ßais (French)\n",
      "‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi)\n",
      "Magyar (Hungarian)\n",
      "Bahasa Indonesia (Indonesian)\n",
      "Italiano (Italian)\n",
      "◊¢◊ë◊®◊ô◊™ (Hebrew)\n",
      "Êó•Êú¨Ë™û (Japanese)\n",
      "ÌïúÍµ≠Ïñ¥ (Korean)\n",
      "‡§Æ‡§∞‡§æ‡§†‡•Ä (Marathi)\n",
      "Bahasa Malaysia (Malay)\n",
      "Nederlands (Dutch)\n",
      "Norsk (Norwegian)\n",
      "‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä (Punjabi)\n",
      "Polski (Polish)\n",
      "Portugu√™s (Portuguese)\n",
      "Rom√¢nƒÉ (Romanian)\n",
      "–†—É—Å—Å–∫–∏–π (Russian)\n",
      "Svenska (Swedish)\n",
      "‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å (Telugu)\n",
      "‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (Thai)\n",
      "Tagalog (Tagalog)\n",
      "T√ºrk√ße (Turkish)\n",
      "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ (Ukrainian)\n",
      "Ti·∫øng Vi·ªát (Vietnamese)\n",
      "ÁÆÄ‰Ωì‰∏≠Êñá (Chinese (Simplified))\n",
      "Ê≠£È´î‰∏≠Êñá (Chinese (Traditional))\n",
      "Language\n",
      "Agree & Join LinkedIn\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Sign in to see who you already know at Hugging Face\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "LinkedIn\n",
      "LinkedIn is better on the app\n",
      "Don‚Äôt have the app? Get it in the Microsoft Store.\n",
      "Open the app\n",
      "\n",
      "\n",
      "\n",
      "Product endpoints\n",
      "Webpage Title:\n",
      "Inference Endpoints by Hugging Face\n",
      "Webpage Contents:\n",
      "Inference\n",
      "Endpoints\n",
      "Catalog\n",
      "Log In\n",
      "Machine Learning At Your Service\n",
      "by\n",
      "Hugging Face\n",
      "Easily deploy your AI models to production on our fully managed platform. Instead of\n",
      "\t\t\t\tspending weeks configuring infrastructure, focus on building you AI application.\n",
      "Log In\n",
      "Learn More\n",
      "No Hugging Face account ?\n",
      "Sign up\n",
      "!\n",
      "One-click deployment\n",
      "Import your favorite model from Hugging Face or browse our catalog of hand-picked, ready-to-deploy models!\n",
      "ibm-granite /\n",
      "granite-3.3-8b-instruct-FP8\n",
      "12\n",
      "Deployed 12 times\n",
      "Text Generation\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "openai /\n",
      "gpt-oss-safeguard-20b\n",
      "24\n",
      "Deployed 24 times\n",
      "Text Generation\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "allenai /\n",
      "olmOCR-2-7B-1025-FP8\n",
      "31\n",
      "Deployed 31 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "Qwen /\n",
      "Qwen3-VL-30B-A3B-Thinking\n",
      "24\n",
      "Deployed 24 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "2x Nvidia A100\n",
      "$\n",
      "5\n",
      "Qwen /\n",
      "Qwen3-VL-8B-Instruct\n",
      "72\n",
      "Deployed 72 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia A100\n",
      "$\n",
      "2.5\n",
      "Browse Catalog\n",
      "Hub Models\n",
      "Trusted By\n",
      "These teams are running AI models on Inference Endpoints\n",
      "Features\n",
      "Everything you need to deploy AI models at scale\n",
      "Fully Managed Infrastructure\n",
      "Don't worry about Kubernetes, CUDA versions, or configuring VPNs. Focus on deploying your model and serving customers.\n",
      "Autoscaling\n",
      "Automatically scales up as traffic increases and down as it decreases to save on compute costs.\n",
      "Observability\n",
      "Understand and debug your model through comprehensive logs & metrics.\n",
      "Inference Engines\n",
      "Deploy with vLLM, TGI, SGLang, TEI, or custom containers.\n",
      "Hugging Face Integration\n",
      "Download model weights fast and securely with seamless Hugging Face Hub integration.\n",
      "Future-proof AI Stack\n",
      "Stay current with the latest frameworks and optimizations without managing complex upgrades.\n",
      "Pricing\n",
      "Choose a plan that fits your needs\n",
      "Self-Serve\n",
      "Pay as you go when using Inference Endpoints\n",
      "Pay for what you use, per minute\n",
      "Starting as low as $0.06/hour\n",
      "Billed monthly\n",
      "Email support\n",
      "See Instance Pricing\n",
      "Enterprise\n",
      "Get a custom quote and premium support\n",
      "Lower marginal costs based on volume\n",
      "Uptime guarantees\n",
      "Custom annual contracts\n",
      "Dedicated support, SLAs\n",
      "Request a Quote\n",
      "Testimonials\n",
      "Hear from our users\n",
      "The coolest thing was how easy it was to define a complete custom interface from the model to the inference process. It just took us a couple of hours to adapt our code, and have a functioning and totally custom endpoint.\n",
      "Andrea Boscarino\n",
      "Data Scientist at Musixmatch\n",
      "It took off a week's worth of developer time. Thanks to Inference Endpoints, we now basically spend all of our time on R&D, not fiddling with AWS. If you haven't already built a robust, performant, fault tolerant system for inference, then it's pretty much a no brainer.\n",
      "Bryce Harlan\n",
      "Senior Software Engineer at Phamily\n",
      "We were able to choose an off the shelf model that's very common for our customers and set it to to handle over 100 requests per second just with a few button clicks. A new standard for easily building your first vector embedding based solution, whether it be semantic search or question answering system.\n",
      "Gareth Jones\n",
      "Senior Product Manager at Pinecone\n",
      "You're bringing the potential time delta between testing and production down to potentially less than a day. I've never seen anything that could do this before. I could have it on infrastructure ready to support an existing product\n",
      "Nathan Labenz\n",
      "Founder at Waymark\n",
      "Ready to Get Started?\n",
      "Join thousands of developers and teams using Inference Endpoints to deploy their AI models\n",
      "\t\t\t\tat scale. Start building today with our simple, secure, and scalable infrastructure.\n",
      "Get Started for Free\n",
      "View Documentation\n",
      "\n",
      "\n",
      "\n",
      "Discord community\n",
      "Webpage Title:\n",
      "Hugging Face\n",
      "Webpage Contents:\n",
      "You need to enable JavaScript to run this app.\n",
      "\n",
      "\n",
      "\n",
      "Changelog\n",
      "Webpage Title:\n",
      "Changelog - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Changelog\n",
      "Keep track of latest changes on the Hugging Face Hub\n",
      "Dec 8, 25\n",
      "Upvote\n",
      "42\n",
      "+37\n",
      "Dec 8, 25\n",
      "Team & Enterprise Articles Now Featured on the Hugging Face Blog\n",
      "Upvote\n",
      "42\n",
      "+37\n",
      "Articles published by\n",
      "Team\n",
      "or\n",
      "Enterprise\n",
      "organizations with 30+ seats will be featured in the main section of the\n",
      "Hugging Face Blog\n",
      ". This update gives companies and teams increased visibility and makes it easier for AI builders across the community to discover high-quality technical content, announcements, and tutorials from\n",
      "leading organizations\n",
      ".\n",
      "Dec 3, 25\n",
      "Upvote\n",
      "73\n",
      "+68\n",
      "Dec 3, 25\n",
      "Duplicate Datasets\n",
      "Upvote\n",
      "73\n",
      "+68\n",
      "You can now duplicate any Dataset directly on the Hugging Face Hub, making it easier to experiment, modify, or extend existing datasets.\n",
      "Thanks to\n",
      "Xet deduplication technology\n",
      ", duplication is nearly instant, allowing you to create your own copy and start iterating right away.\n",
      "Nov 28, 25\n",
      "Upvote\n",
      "73\n",
      "+68\n",
      "Nov 28, 25\n",
      "Add a Status to your Hugging Face profile\n",
      "Upvote\n",
      "73\n",
      "+68\n",
      "Profile statuses are here‚Äîpick ‚ÄúOpen to Work‚Äù ‚ÄúOpen to Collab‚Äù ‚ÄúHiring üíº‚Äù and more!\n",
      "The label shows right on your avatar, so everyone knows what you‚Äôre up to in one look. ü§©\n",
      "Nov 25, 25\n",
      "Upvote\n",
      "53\n",
      "+48\n",
      "Nov 25, 25\n",
      "Featured Spaces are now easier to spot\n",
      "Upvote\n",
      "53\n",
      "+48\n",
      "Featured Spaces (Spaces of the Week) are now marked with a üî• icon, making them easier to identify at a glance. This update helps you quickly find standout projects curated by the Hugging Face team.\n",
      "Nov 7, 25\n",
      "Upvote\n",
      "88\n",
      "+83\n",
      "Nov 7, 25\n",
      "Hugging Face App on Okta Integration Network\n",
      "Upvote\n",
      "88\n",
      "+83\n",
      "Our official app is now listed on the\n",
      "Okta Integration Network (OIN)\n",
      "and available to all Okta users. Organizations get a trusted, pre-validated integration that makes SSO setup easier and onboarding faster. The app currently supports SAML, with OIDC, SCIM, and JIT provisioning coming soon.\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "6\n",
      "Next\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Careers\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fetch_page_and_all_relevant_links(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages;\n",
    "use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
    "\"\"\"\n",
    "    user_prompt += fetch_page_and_all_relevant_links(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nHugging Face ‚Äì The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nmicrosoft/VibeVoice-Realtime-0.5B\\nUpdated\\n3 days ago\\n‚Ä¢\\n80.2k\\n‚Ä¢\\n733\\nTongyi-MAI/Z-Image-Turbo\\nUpdated\\n3 days ago\\n‚Ä¢\\n245k\\n‚Ä¢\\n2.55k\\nzai-org/GLM-4.6V-Flash\\nUpdated\\n2 days ago\\n‚Ä¢\\n18.6k\\n‚Ä¢\\n350\\nzai-org/GLM-4.6V\\nUpdated\\n3 days ago\\n‚Ä¢\\n2.21k\\n‚Ä¢\\n268\\nmistralai/Devstral-Small-2-24B-Instruct-2512\\nUpdated\\n1 day ago\\n‚Ä¢\\n7.22k\\n‚Ä¢\\n267\\nBrowse 1M+ models\\nSpaces\\nRunning\\non\\nZero\\nMCP\\nFeatured\\n1.31k\\nZ Image Turbo\\nüèÉ\\n1.31k\\nGenerate images from text prompts\\nRunning\\non\\nZero\\n479\\nZ Image Turbo\\nüñº\\n479\\nGenerate stunning images from text prompts\\nRunning\\n181\\nEvaluation Guidebook\\nüìù\\n181\\nDisplay evaluation metrics for LLM benchmarks\\nRunning\\non\\nZero\\nMCP\\nFeatured\\n906\\nDream-wan2-2-faster-Pro\\nüé¨\\n906\\nGenerate videos from images using prompts\\nRunning\\non\\nZero\\nMCP\\nFeatured\\n1.58k\\nQwen Image Edit Camera Control\\nüé¨\\n1.58k\\nFast 4 step inference with Qwen Image Edit 2509\\nBrowse 400k+ applications\\nDatasets\\nAnthropic/AnthropicInterviewer\\nUpdated\\n3 days ago\\n‚Ä¢\\n7.04k\\n‚Ä¢\\n223\\nTuringEnterprises/Turing-Open-Reasoning\\nUpdated\\n6 days ago\\n‚Ä¢\\n5.96k\\n‚Ä¢\\n98\\nnvidia/PhysicalAI-Autonomous-Vehicles\\nUpdated\\n6 days ago\\n‚Ä¢\\n183k\\n‚Ä¢\\n500\\nnvidia/ToolScale\\nUpdated\\n15 days ago\\n‚Ä¢\\n2.44k\\n‚Ä¢\\n115\\nopenai/gdpval\\nUpdated\\nSep 25\\n‚Ä¢\\n25.1k\\n‚Ä¢\\n344\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nInference Providers\\nAccess 45,000+ models from leading AI providers through a single, unified API with no service fees.\\nExplore Models\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nTeam\\nnon-profit\\n‚Ä¢\\n821 models\\n‚Ä¢\\n4.75k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.27k models\\n‚Ä¢\\n9.81k followers\\nAmazon\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n3.64k followers\\nGoogle\\nEnterprise\\ncompany\\n‚Ä¢\\n1.05k models\\n‚Ä¢\\n38.1k followers\\nIntel\\ncompany\\n‚Ä¢\\n261 models\\n‚Ä¢\\n3.27k followers\\nMicrosoft\\nEnterprise\\ncompany\\n‚Ä¢\\n428 models\\n‚Ä¢\\n17k followers\\nGrammarly\\nTeam\\ncompany\\n‚Ä¢\\n11 models\\n‚Ä¢\\n196 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n32 models\\n‚Ä¢\\n371 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n153,757\\nState-of-the-art AI models for PyTorch\\nDiffusers\\n32,032\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,547\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n3,120\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n10,300\\nFast tokenizers optimized for research & production\\nTRL\\n16,615\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n15,074\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n24,388\\nSmol library to build great agents in Python\\nPEFT\\n20,259\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,977\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,697\\nServe language models with TGI optimized toolkit\\nAccelerate\\n9,366\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nChangelog\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nCareers\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nhomepage\\nWebpage Title:\\nHugging Face ‚Äì The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nmicrosoft/VibeVoice-Realtime-0.5B\\nUpdated\\n3 days ago\\n‚Ä¢\\n80.2k\\n‚Ä¢\\n733\\nTongyi-MAI/Z-Image-Turbo\\nUpdated\\n3 days ago\\n‚Ä¢\\n245k\\n‚Ä¢\\n2.55k\\nzai-org/GLM-4.6V-Flash\\nUpdated\\n2 days ago\\n‚Ä¢\\n18.6k\\n‚Ä¢\\n350\\nzai-org/GLM-4.6V\\nUpd'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44de579-4a1a-4e6a-a510-20ea3e4b8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093444a-9407-42ae-924a-145730591a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hugging Face: The AI community building the future\n",
       "\n",
       "The AI community building the future. The platform where the machine learning community collaborates on models, datasets, and applications.\n",
       "\n",
       "---\n",
       "\n",
       "## Who we are (in a sentence and a joke)\n",
       "\n",
       "- The Home of Machine Learning, where creators, researchers, and everyone in between can create, discover, and collaborate on ML faster.\n",
       "- A global open-source playground with enterprise-grade options for teams that need a little more gravity than a weekend hackathon.\n",
       "- If your model could use a bigger crowd, you‚Äôre in the right place.\n",
       "\n",
       "Humor aside: we‚Äôre basically the coffee shop for ML‚Äîlots of activity, great people, and everyone leaves with a better model.\n",
       "\n",
       "---\n",
       "\n",
       "## What you can do with Hugging Face\n",
       "\n",
       "- Browse 1M+ models and explore AI Apps\n",
       "- Run Spaces and deploy your ideas with a click\n",
       "- Use an open-source stack that moves the field forward\n",
       "- Access 45,000+ models from leading AI providers through a single, unified API with no service fees\n",
       "- Work with diverse modalities: text, image, video, audio, and even 3D\n",
       "\n",
       "Open-source backbone (the brain of the operation):\n",
       "- Transformers, Diffusers, Tokenizers, Safetensors, PEFT, TRL, Transformers.js, and more\n",
       "- Datasets, Text Generation Inference, Accelerate, and other tools that help you build faster\n",
       "\n",
       "---\n",
       "\n",
       "## Enterprise & pricing (for teams that mean business)\n",
       "\n",
       "- Team & Enterprise plans starting at $20 per user per month\n",
       "- Single Sign-On, Regions, Priority Support, Audit Logs, Resource Groups, Private Datasets Viewer\n",
       "- Inference Endpoints: deploy on optimized endpoints or scale your Spaces with GPU in a few clicks\n",
       "- GPU pricing starting at $0.60/hour\n",
       "- More than 50,000 organizations are using Hugging Face (yep, a lot of friends and colleagues)\n",
       "\n",
       "Ready to go from hobbyist corner to enterprise-grade? We‚Äôve got you.\n",
       "\n",
       "---\n",
       "\n",
       "## Customers & community\n",
       "\n",
       "- Trusted by a global roster of organizations and teams\n",
       "- Examples include AI2 Team, AI at Meta, Amazon, Google, Intel, Microsoft, Grammarly, Writer\n",
       "- It‚Äôs not just about the tech; it‚Äôs about the people building, sharing, and improving together\n",
       "\n",
       "The platform is built for collaboration: host and collaborate on unlimited public models, datasets, and applications, and accelerate your ML work with the Open Source stack.\n",
       "\n",
       "---\n",
       "\n",
       "## Careers & culture\n",
       "\n",
       "- We‚Äôre building the foundation of ML tooling with the community.\n",
       "- A culture of collaboration, openness, and curiosity‚Äîplus a dash of humor to keep things human.\n",
       "- See our Careers page for the latest openings and opportunities to join the team that‚Äôs shaping the future of AI.\n",
       "\n",
       "If you like working with smart people on impactful projects, you‚Äôll feel right at home here.\n",
       "\n",
       "---\n",
       "\n",
       "## Get started quickly\n",
       "\n",
       "- Sign up and explore: Browse 1M+ models, explore AI Apps, or dive into Spaces\n",
       "- Sign in to access tools that fit your workflow\n",
       "- Start building with a robust open-source stack and enterprise-ready options\n",
       "\n",
       "Bonus: you‚Äôll be in excellent company‚Äîyour models will thank you, your data will thank you, and your ego might need a little room to swell.\n",
       "\n",
       "---\n",
       "\n",
       "## Quick pull quotes (so you can skim)\n",
       "\n",
       "- ‚ÄúThe AI community building the future.‚Äù \n",
       "- ‚ÄúThe platform where the machine learning community collaborates on models, datasets, and applications.‚Äù\n",
       "- ‚ÄúMove faster with the HF Open source stack.‚Äù\n",
       "- ‚ÄúAccess 45,000+ models from leading AI providers through a single, unified API with no service fees.‚Äù\n",
       "- ‚ÄúMore than 50,000 organizations are using Hugging Face.‚Äù\n",
       "\n",
       "---\n",
       "\n",
       "Ready to join the party? Explore Models, Datasets, Spaces, and more at Hugging Face today."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hugging Face ‚Äì The AI community building the future\n",
       "\n",
       "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
       "\n",
       "---\n",
       "\n",
       "## Why Hugging Face\n",
       "\n",
       "- Open, community-driven foundation for ML tooling and collaboration\n",
       "- Host and collaborate on unlimited public models, datasets, and applications\n",
       "- Move faster with the HF Open Source stack\n",
       "- Support for all modalities: text, image, video, audio, or even 3D\n",
       "- Build your ML portfolio and share your work with the world\n",
       "\n",
       "---\n",
       "\n",
       "## Products & Platforms\n",
       "\n",
       "- Models\n",
       "  - Browse 1M+ models from the community and leading providers\n",
       "  - Access 45,000+ models from various providers through a single, unified API\n",
       "- Datasets\n",
       "  - Access and share datasets for any ML task\n",
       "- Spaces\n",
       "  - Run interactive ML apps, demos, and experiments\n",
       "- Enterprise & Pricing\n",
       "  - Team & Enterprise plans with enterprise-grade security, access controls, and dedicated support\n",
       "  - Getting started from $20 per user/month (significant features like SSO, audit logs, regions, etc.)\n",
       "  - Compute options: Inference Endpoints and GPU-backed Spaces\n",
       "- Inference & Acceleration\n",
       "  - Deploy on optimized Inference Endpoints\n",
       "  - GPU-based scaling options starting at $0.60/hour\n",
       "- Community & Docs\n",
       "  - Rich documentation, forums, and a thriving developer community\n",
       "- Sign Up / Sign In\n",
       "  - Join the community to start creating, sharing, and collaborating\n",
       "\n",
       "---\n",
       "\n",
       "## Our Open Source Foundation\n",
       "\n",
       "We‚Äôre building the foundation of ML tooling with a vibrant open source ecosystem. Notable projects and their scale include:\n",
       "\n",
       "- Transformers: 153,816\n",
       "- Diffusers: 32,040\n",
       "- Safetensors: 3,548\n",
       "- Hub Python Library: 3,131\n",
       "- Tokenizers: 10,302\n",
       "- TRL: 16,635\n",
       "- Transformers.js: 15,080\n",
       "- smolagents: 24,406\n",
       "- PEFT: 20,269\n",
       "\n",
       "Plus, a broad ecosystem around Datasets, Text Generation Inference, and Accelerate.\n",
       "\n",
       "---\n",
       "\n",
       "## Customers & Partnerships\n",
       "\n",
       "Join 50,000+ organizations leveraging Hugging Face for ML development, deployment, and collaboration. Notable customers and partners include:\n",
       "\n",
       "- Ai2 (non-profit)\n",
       "- AI at Meta\n",
       "- Amazon\n",
       "- Google\n",
       "- Intel\n",
       "- Microsoft\n",
       "- Grammarly\n",
       "- Writer\n",
       "\n",
       "These organizations rely on Hugging Face for access to vast model catalogs, datasets, and scalable deployment.\n",
       "\n",
       "---\n",
       "\n",
       "## Careers & Culture\n",
       "\n",
       "- Hugging Face publishes a Careers page with opportunities across teams.\n",
       "- Culture emphasizes collaboration, openness, and contribution to the open source ML ecosystem.\n",
       "- A community-first mindset: collaborate on models, datasets, and apps to advance the field together.\n",
       "- If you‚Äôre passionate about AI, open source tooling, and building with others, consider joining the team.\n",
       "\n",
       "---\n",
       "\n",
       "## Get Involved\n",
       "\n",
       "- Explore Models, Datasets, and Spaces\n",
       "- Sign up to build your ML portfolio and share your work\n",
       "- For enterprises, explore Team & Enterprise plans with security, governance, and dedicated support\n",
       "- Visit the Careers page to learn about current openings\n",
       "\n",
       "Links you might find useful:\n",
       "- Docs, Blog, Forum\n",
       "- Inference Endpoints, Spaces, and Models\n",
       "- Sign Up / Log In\n",
       "- Careers, Press, About, Privacy, Terms\n",
       "- Social: GitHub, Twitter, LinkedIn, Discord\n",
       "\n",
       "---\n",
       "\n",
       "Hugging Face is the AI community building the future ‚Äî a collaborative, open, and scalable platform for models, data, and applications. Whether you‚Äôre a researcher, engineer, data journalist, product builder, or a prospective recruit, there‚Äôs a place for you in the community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face ‚Äî The AI community building the future\n",
       "\n",
       "Welcome to the place where models, datasets, and spaces make friends, not friction. We‚Äôre the collaboration platform for the machine learning crowd ‚Äî from researchers to developers to folks who just want to see cool AI in action.\n",
       "\n",
       "## Who we are (in one sentence, with snacks)\n",
       "\n",
       "- The Home of Machine Learning: a supercharged hub to create, discover, and collaborate on ML projects.\n",
       "- The Open Source Engine: our stack powers transformers, diffusers, and a bazillion tiny miracles that make ML go vroom.\n",
       "- The Community Engine: a global crew of engineers, scientists, and end users learning, sharing, and cheering each other on.\n",
       "\n",
       "Humor aside, we mean business: innovation, openness, and helping you move faster than a caffeinated dataset.\n",
       "\n",
       "## What you can do here\n",
       "\n",
       "- Browse 1M+ models: from zippy image generators to speech founts and everything in between.\n",
       "- Explore 400k+ applications: deploy ideas as live apps you can actually use.\n",
       "- Dive into 250k+ datasets: practice, test, and train with real-world data.\n",
       "- Run Spaces: host and run your ML apps with a few clicks (they‚Äôre ‚ÄúRunning‚Äù and sometimes ‚ÄúMCP‚Äù ‚Äî we‚Äôre keeping you on your toes).\n",
       "\n",
       "For the cool kids who like to go beyond plain text:\n",
       "- Work across all modalities: text, image, video, audio, or even 3D.\n",
       "\n",
       "## Our open source stack (the backbone of modern ML)\n",
       "\n",
       "‚ÄúOpen source first‚Äù isn‚Äôt a slogan here ‚Äî it‚Äôs how we breathe.\n",
       "- Transformers, Diffusers, Tokenizers, and more ‚Äî with millions of models and tools at your fingertips.\n",
       "- Safe, easy storage and transfer with Safetensors.\n",
       "- In-browser ML with Transformers.js.\n",
       "- Tools to fine-tune efficiently (PEFT) and build smarter agents (smolagents).\n",
       "\n",
       "If you like APIs, you‚Äôll love the single unified API that reaches 45,000+ models from leading AI providers ‚Äî with no service fees. We‚Äôre basically the Swiss Army knife for ML developers.\n",
       "\n",
       "## Why customers love Hugging Face (and why investors might grin)\n",
       "\n",
       "- A massive, growing community of users and contributors (50,000+ organizations rely on us).\n",
       "- Enterprise-grade options: Team & Enterprise features include security, access controls, priority support, SSO, audit logs, resource grouping, private datasets, and more.\n",
       "- Compute that scales: deploy on optimized Inference Endpoints or upgrade Spaces to GPU in just a few clicks.\n",
       "- Transparent pricing that starts at approachable levels (Getting started: from $20/user/month; GPU compute from $0.60/hour).\n",
       "- A portfolio of big-name users and partners (Meta, Amazon, Google, Intel, Microsoft, Grammarly, Writer, and many more) showing that real organizations trust our platform.\n",
       "\n",
       "And yes, we‚Äôre serious about safety, governance, and making ML tools accessible to builders of all stripes. Hugging Face isn‚Äôt just a brand ‚Äî it‚Äôs a movement toward collaboration, openness, and shared progress.\n",
       "\n",
       "## Culture you‚Äôll actually want to work with\n",
       "\n",
       "- Open, collaborative, and community-driven: your ideas matter; your pull requests matter more.\n",
       "- Cross-disciplinary vibes: engineers, researchers, data folks, designers, and product folks all building together.\n",
       "- A love for sharing what we learn: docs, blogs, forums, and discussions that help everyone level up.\n",
       "- A sense of humor about AI, and a passion for making tools that are powerful yet approachable.\n",
       "\n",
       "We‚Äôre not just about doing cool stuff; we‚Äôre about doing it together and helping the next generation of ML engineers, scientists, and end users learn, collaborate, and share their work with the world.\n",
       "\n",
       "## Careers & opportunities\n",
       "\n",
       "- Careers at Hugging Face: a place where you can build, contribute, and grow in a culture of openness and collaboration.\n",
       "- What you‚Äôll find: a team that values initiative, curiosity, and a friendly poke at each other‚Äôs code (in good spirits).\n",
       "- Roles span engineering, research, product, operations, and community/community governance ‚Äî all with a front-row seat to the future of ML tooling.\n",
       "- Perks include meaningful work on a thriving open-source stack, opportunities to impact ML at scale, and a place in a global community of ML enthusiasts.\n",
       "\n",
       "If you‚Äôre excited by the idea of shaping the next era of AI tooling, you‚Äôll feel right at home.\n",
       "\n",
       "## Brand vibe (so you know what we look like)\n",
       "\n",
       "- Colors: vibrant HF yellow/orange hues (#FFD21E, #FF9D00) with the calm neutral gray (#6B7280).\n",
       "- Brand promise: the collaboration platform for the machine learning community.\n",
       "- Visuals emphasize sharing, discovery, and experimentation in an open, friendly way.\n",
       "\n",
       "Brand assets and a clear identity back up a culture that‚Äôs playful, pragmatic, and built for collaboration.\n",
       "\n",
       "## Quick-start for you\n",
       "\n",
       "- Sign Up and join the community.\n",
       "- Explore 1M+ models, 400k+ apps, and 250k+ datasets.\n",
       "- Use Spaces to run your apps or spin up GPUs in a few clicks.\n",
       "- If you‚Äôre a team or enterprise, check out Team & Enterprise for security, governance, and dedicated support.\n",
       "- Dive into our open-source stack to see what powers modern ML tooling.\n",
       "\n",
       "## Closing note (because who doesn‚Äôt like a good send-off?)\n",
       "\n",
       "Hugging Face is more than a platform ‚Äî it‚Äôs a friendly, ambitious ecosystem where you can hug (figuratively, of course) the future of AI by collaborating with the world. Whether you‚Äôre a customer shipping production ML, an investor watching the network effects unfold, or a candidate hunting for a meaningful, fun career, we‚Äôve got a seat at the table.\n",
       "\n",
       "Want to learn more or start building with us? Sign up, explore, and let‚Äôs Hugging Face the future together."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype. See what other students have done in the community-contributions folder -- so many valuable projects -- it's wild!</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 3 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!<br/>\n",
    "            3. I'm trying out X/Twitter and I'm at <a href=\"https://x.com/edwarddonner\">@edwarddonner<a> and hoping people will teach me how it's done..  \n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48e42e-fa7a-495f-a5d4-26bfc24d60b6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Finally! I have a special request for you</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                My editor tells me that it makes a MASSIVE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. If you're able to take a minute to rate this, I'd be so very grateful! And regardless - always please reach out to me at ed@edwarddonner.com if I can help at any point.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
